title,keyword,abstract,field,authors,date,doi,references,id,type
Efficient and flexible lineage construction for probabilistic databases,,"In contrast to traditional data applications, many real-world scenarios nowadays depend on managing and querying huge volumes of uncertain and incomplete data. This new type of applications emerge, for example, when we integrate data from various sources, analyse social/biological/chemical networks or conduct privacy-preserving data mining. A very promising concept addressing this new kind of probabilistic data applications has been proposed in the form of probabilistic databases. Here, a tuple only belongs to its table or query answer with a specific likelihood. That probability expresses the uncertainty about the given data or the confidence in the answer. The most challenging task for probabilistic databases is query evaluation. In fact, there are even simple relational queries for which determining the occurrence probability of a single answer tuple is hard for #P. Lineage formulas constitute the central concept under investigation in this work. In short, the mechanism behind lineage formulas facilitates the representation and evaluation of events of the probability space, which is defined by a probabilistic database. On the basis of lineage formulas, we devise a framework that is designed as a combination of a relational database layer and an additional probabilistic query engine. In particular, the following three aspects are studied: (i) an efficient construction of lineage formulas, (ii) an orthogonal combination of lineage optimization techniques, which are performed within the relational database layer and the probabilistic query engine, and (iii) effective and compact data structures to represent lineage formulas within a probabilistic query engine. The developed framework provides a novel lineage construction method that is able to construct nested lineage formulas, to avoid large tuple sets within the relational database layer tuples, and to provide full relational algebra support. In addition, the proposed system completely resolves the conflict between the contradicting query plans optimized for the relational database layer and the probabilistic query engine.",,"Lehrack, Sebastian",2016,,,OPUS4-4046,Dissertation
Optimization problem of portfolios with an illiquid asset,,"This work is devoted to the problem of liquidity that draws a lot of attention after the global financial crisis. We consider an optimization problem for a portfolio with an illiquid, a risky and a riskless liquid asset. We work in Merton's optimal consumption framework with continuous time. The liquid part of the investment is described by a standard Black-Scholes market. The illiquid asset is sold at an exogenous random moment with prescribed distribution and generates additional liquid wealth dependent on its paper value. We show that one can consider a problem with infinite time horizon and special weight function that is characterized by the probability distribution of the liquidation time instead of a problem with an exogenous random liquidation time. Using the viscosity solution techniques, developed for the problem of optimization in presence of a random income, we prove the existence and uniqueness of the solution for the considered problem with logarithmic utility and modest restrictions on the liquidation time distribution. We find asymptotic bounds for the value function when liquidation time has exponential or Weibull distribution. We find optimal policies in a feedback form and illustrate how they differ from classical Merton's policies. Through a Lie group analysis we find the admitted Lie algebra for a problem with general liquidation time distribution in cases of HARA and log utility functions and formulate corresponding theorems for all these cases. Using these Lie algebras we obtain reduced equations of the lower dimension for the studied three dimensional partial differential equations. Several of similar substitutions were used in other works before, whereas others are new to our knowledge. The applied method of Lie group analysis gives us the possibility to provide a complete set of non-equivalent substitutions and reduced equations that was not provided for the problem of such type so far. Further research of these equations with numerical and quantitative methods is expected to benefit from such analysis.",,"Yamshchikov, Ivan P.",2016,,,OPUS4-3992,Dissertation
On the applicability of short key asymmetric cryptography in low power wireless sensor networks,,"The growing popularity of Wireless Sensor Networks (WSN) makes the spectrum of their applications very wide. A great number of the application areas like health monitoring or military applications require a high level of security and dependability from the wireless sensor network. Solving these issues can be supported by providing cryptographic solutions into WSN applications. Since the WSNs mainly consist of low power devices, cryptographic solutions ideal for WSNs should provide computationally lightweight security mechanisms producing small data packets and ensuring confidentiality. Cryptographic mechanisms that have both these features are considered in this thesis, which main objective is the analysis of the applicability of the short key elliptic curve cryptography in WSN environments. Reduced key lengths require modification of the standard ECC security algorithms to provide authentication and also a novel solution for a cryptographic secure pseudo-random number generator. The proposed solution is based on the standard ECC, but it differs in several aspects. The main difference is that the parameters of the used elliptic curve have to be kept secret. This is due to the fact that solving the Discreet Logarithm Problem (DLP) for such short parameters can be done in short time. Additionally, using shorter parameters for the underlying elliptic curves excludes also the use of standard hash functions, what mainly influences the mechanisms for generating the digital signature. Hash functions require large input values and produce relatively large output data that is inapplicable in the shortECC environment. Thus, within this thesis a modified version of standard Elliptic Curves Digital Signature Algorithm is proposed, which does not require any hash function. The shortECC needs pseudo-random numbers in the encryption and the digital signature protocols, but since it operates on numbers that are significantly shorter than the ones used by other cryptographic approaches, pseudo-random number generators for standard approaches are not suitable for shortECC. Thus, the new pseudo-random number generator not involving any additional hardware besides the modules available on the used test platform and operating on 32-bit long integers, is proposed. The randomness of the numbers generated by the proposed algorithm and their applicability for cryptographic purposes was evaluated using the NIST test suites. The shortECC approach was also subjected to cryptanalysis in order to proof its security and determine the circumstances and constraints for its application.",,"Sojka-Piotrowska, Anna",2016,,,OPUS4-3945,Dissertation
Controlling entrainment in large-eddy simulation of stratocumulus clouds,,"A front-tracking algorithm for large-eddy simulation (LES) is developed to untangle the numerical and physical contributions to entrainment in stratocumulus-topped boundary layers. The front-tracking algorithm is based on the level set method. Instead of resolving the cloud-top inversion, it is represented as a discontinuous interface separating the boundary layer from the free atmosphere. The location of the interface is represented as an isosurface of an evolving marker function the evolution of which is governed by an additional transport equation. The algorithm has been implemented in an existing LES code based on the anelastic approximation of the Navier-Stokes equations. The original LES algorithm is verified against direct-numerical simulation (DNS) data of an idealized two-dimensional cloud-top mixing layer. For this, the subgrid-scale model of the LES code was replaced by a constant molecular viscosity in order to focus on numerical errors only. A grid convergence study confirmed the anticipated global second-order rate of convergence and the convergence to the DNS solution. The slower convergence of the LES code as compared to the higher-order DNS yielded leading-order errors in the mixing layer growth at the coarsest resolutions, which were finer still than typical LES resolutions. The front-tracking algorithm is verified by LESs of two different convective atmospheric boundary layers: the smoke cloud, a solely radiatively driven boundary layer, and a stratocumulus-topped boundary layer based on data from the DYCOMS II field study. Specifying zero entrainment, it was shown that entrainment in LES can be controlled effectively by the front-tracking algorithm. The algorithm drastically reduces entrainment errors and reduces dependencies of the solution to numerical parameters such as the choice of flux-limiters and grid resolution.",,"Kadasch, Eckhard",2016,,,OPUS4-4039,Dissertation
Seamless integration of smart objects into the internet using XMPP and mDNS/DNS-SD,,"With the integration of smart objects into the Internet users should gain new possibilities to directly interact with their physical environment. This vision is called Internet of Things (IoT) and is enabled by the development of micro Internet Protocol (IP) stacks that allow one to directly connect smart objects to the Internet. IP alone cannot ensure a seamless integration because advanced services (e.g., service discovery, identity management) can only be provided at the application layer. The current development of application protocols for the IoT focuses on the Machine-to-Machine (M2M) communication and introduces specialized protocol gateways, smart object-specific code or data representations that hinder a seamless integration. This thesis deals with the seamless integration, discovery, and employment of smart objects into the current Internet infrastructure under Human-to-Machine (H2M) communication aspects by using and adapting already established protocols that have been standardized by the Internet Engineering Task Force (IETF), such as the Extensible Messaging and Presence Protocol (XMPP), Multicast DNS (mDNS), and DNS Service Discovery (DNS-SD). The proposed approach is called Chatty Things. So smart objects may become a natural part of the network making the IoT readily usable for (non-technical) users and network administrators providing them with the same level of usability that is predominant in the current Internet infrastructure. The applicability of XMPP and mDNS/DNS-SD for smart objects has been evaluated with implementations of minimized, modular, and extensible software stacks for the IoT operating system Contiki. This includes a readily usable Application Programming Interface (API), an essential set of XMPP extension protocols, a proposal for lightweight and user-friendly event notification, a standardized bootstrapping, and a seamless fallback mechanism for ad hoc use cases when infrastructure services are failing for XMPP-driven smart objects. Furthermore, this thesis presents optimizations for the used protocols to reduce the network traffic in low data rate smart object networks (e.g., sensor-specific groups, enhanced message compression mechanisms). To sum up, this thesis shows how XMPP and mDNS/DNS-SD can be used economically on smart objects for the seamless integration with low effort into the current Internet infrastructure to enable a transparent (H2M) interaction and service discovery for the IoT.",,"Klauck, Ronny",2016,,,OPUS4-3850,Dissertation
"Shared heritage: Sacred landscapes of Crimea, their development and protection in the multicultural context",,"Owing to its unique strategic position on the northern coast of the Black Sea, Crimea has, since Antiquity, been a highly diverse, multi-ethnic, multi-religious location. Throughout history, the peninsula's landscapes were shaped and transformed under the influence of its ever-changing populations. In this process, religion played a crucial role. Nowadays, Crimea abounds in sacred sites in the same way as it abounds in culturally and religiously diverse inhabitants. Rebirth in the 1990s of the religious and cultural life that had been repressed for over seventy years of the Soviet rule gave a powerful impetus to the revival of Crimea's sacred landscapes and enabled the different ethno-religious groups residing in the peninsula to re-establish the bond with the home of their ancestors. The notion of landscape as a memoryscape became central in this context, since it is the landscape that records, as well as reflects, the events in history. The sites communally regarded as sacred unite the people as much as common memories transmitted from one generation to the other do. The objectives of the theoretical part of this thesis are twofold. On the one hand, it aims to grasp the connection between religion, landscape and memory, whereby sacred sites are seen as landscapes of memory and anchors of people's cultural and religious identity. On the other hand, it seeks to explore the specific issues pertinent to the Crimean socio-cultural context, such as the peninsula's history and the evolving ethno-religious relationships among the diverse local population, which have impacted the development and protection of Crimea's sacred sites overtime. Method employed is the comparative literature review, whereby for each chapter a selection of authors was made, whose contributions towards the discussion of the aforementioned issues have been particularly relevant. Based on the theoretical background described above, the empirical section of the research targets two main groups of actors: the state on the one side, and the organizations representing local religious groups on the other. In relation to the state, the objective is to explore how the religious revival of the post-Soviet period correlates with Ukraine's current policies towards the safeguarding of Crimea's sacred landscapes, namely, to what extent they are being protected under the existing legislation, and which of the aspects are given most attention in the process. In relation to the organizations representing local religious groups, the task is to investigate to what degree the sacred sites under study remain relevant for various groups, and to establish how the knowledge about the local sacred places and their importance is being disseminated both within these groups and beyond. In order to fulfill these tasks, the set of indicators has been developed, which takes into consideration the specific Crimean socio-cultural context, and a selection of case studies has been made, which in their totality reflect the viewpoints of Crimea's prominent religious groups. The case studies are: (1) the Assumption Monastery, (2) the cave town of Chufut Kale with Balta Tiymez Karaite cemetery, and (3) the old town of Bakhchisaray with Salachiq historic district and Gazy Mansur cemetery. All of the three case studies are located on the territory of Bakhchisaray Historical and Cultural Preserve (BHCP). The evaluation of the Ukrainian state's policies with regards to safeguarding of the selected sacred sites revealed that while many of their elements are recognized as cultural heritage of high significance, protection activities are impeded by substantial obstacles of administrative nature, as well as by the lack general planning. Moreover, conservation and day-to-day management is carried out with little consideration for the opinions of the local people and with the insufficient involvement of the latter. The indicator-based assessment of relevance of the selected sacred locations for various local religious groups and the ways, in which the knowledge about these sites is being spread exposed a number of clear tendencies, as well as highlighted the existing challenges and deficiencies which need to be urgently addressed, so as to ensure the safeguarding of the studied sites for the future generations.",,"Afanasyeva, Dariya",2015,,,OPUS4-3593,Dissertation
Investigation of high Reynolds number pipe flow - CoLaPipe experiments,,"Investigations of high Reynolds number pipe flow is up to now a great challenge due to the complex mechanisms which appear in pipe flow turbulence. Hence, suitable experimental facilities are necessary to resolve turbulent dynamics and therewith to provide the knowledge for the understanding of such a simple shear flow. For this reason the recent thesis deals with conceptual design and setup of a new high Reynolds number pipe test facility further on named CoLaPipe - Cottbus Large Pipe. It also comprises first investigations on pipe flow obtained from the new CoLaPipe, which can be classified into 1.)calibration measurements to put the facility into service and 2.)continuative measurements to provide experimental results helping to understand pipe flow. The first results within the CoLaPipe show that this new experimental facility is suitable to investigate turbulence at high Reynolds numbers, where this conclusion can be drawn from intensive investigations on the development length of the flow either for natural and artificial transition. From further experiments on the evaluation of the wall friction velocity using different estimation methods great difficulties and variations in the calculated values are obtained. These deviations are directly related to the scaling behavior of the mean and fluctuating velocity, which is also shown within this thesis and intensively discussed. Among the discussion of the setup of the new CoLaPipe and the first experimental results this thesis contains a broad literature review with the focus on high and very high Reynolds numbers. Nevertheless, pipe flow at low and moderate Reynolds numbers is described as well.",,"König, Franziska",2015,,,OPUS4-3539,Dissertation
Advanced aero engine common preliminary design environment for the automatic construction of secondary air system and thermal models,,"The state of the art in aero engine design and analysis methods is based on mature computer programs, which have been developed during several decades. The classical approach to the preliminary design phase of engine subsystems is to split the complex engineering process into disciplines and subtasks. Different experts manage the time-consuming modelling work. Due to the increasing demand for higher aero engine performance and design cycle time reduction, process integration, accuracy and agility have become key assets of the engineering work-flow. The intention of this work is to show how multi-disciplinary integration, work-flow automation and CFD-enhanced thermal modelling methods can be used efficiently to support the aero engine preliminary design phase, with focus on the high pressure turbine subsystem. A Java based common design environment for the engine secondary air system, rotors and thermal design disciplines has been developed. This design environment enables the automatic generation of CAD, flow network and thermal models. The improvements in terms of process agility and model prediction accuracy are demonstrated with the application of the implemented process to a reference high pressure turbine subsystem. For validation purposes, the preliminary design definition of the reference turbine case is reproduced. The automatically generated secondary air system and thermal models can replicate the same level of detail as the previous manual approach. It was found that the CFD-enhanced thermal model improves the prediction accuracy in the preliminary design stage, when no engine test data is available.",,"Rey Villazón, Jose María",2015,,,OPUS4-3601,Dissertation
Reciprocal influences of microbial community and hydrogeomorphology in sandy streambeds,,"The main goal of this dissertation was to explore the interactions between the hydrogeomorphology of the streambed in sandy lowland low-order streams and the microbial community inhabiting it. In particular, (i) the influence of the vertical water exchange across the streambed and (ii) of the sediment transport on the function and structure of the streambed microbial community, (iii) and the potential of the microbial community to influence these physical factors were explored. The influences were studied with a model system approach (micro- and mesocosms). Firstly, I examined the significance of vertical water exchange across the streambed for the microbial community. I determined the differences in the microbial community structure and function associated with sediments of differing grain sizes. The grain sizes differed in surface-to-volume ratio and hydraulic conductivity. The results revealed vertical water exchange as the major factor for the structure and function of the microbial community. Secondly, I studied the ability of the microbial community to influence the vertical water exchange across two sandy streambeds: leveled and rippled. My results showed that the microbial community can reduce and even block the vertical water exchange by reducing pore space with gas bubbles formed due to high primary production. Thirdly, I determined the effect of short-term sediment transport events on the function of the microbial community and on the influence of the microbial community on vertical water exchange. The results show that the mechanical stress associated with short-term sediment transport events does not influence the microbial community function. However, a single short-term sediment transport event increased vertical water exchange by (i) releasing the gas bubbles produced by the microbial community and (ii) creating irregularities in the flume bed. Lastly, I ascertained the potential of benthic algal mats to transport sediment by means of buoyancy-mediated detachment from the bed. The results revealed the detachment of algal mats as a novel mechanism of sediment transport during low-flow periods. Overall, the interactions studied show that in sandy streambeds (i) the pattern of vertical water exchange is the primary physical template for the microbial community, and (ii) the activity of the microbial community and sediment transport are stochastic sources of spatiotemporal heterogeneity in vertical water exchange. These results contribute to the understanding and prediction of stream ecosystem functions in sandy streams, which is of special significance in light of the increase in fine sediment load in streams worldwide.",,"Mendoza-Lera, Clara",2015,,,OPUS4-3517,Dissertation
The impact of discharge regulation on microbial sediment respiration at a land-water-interface of the river Spree,,"Flooding of dry sediments is known to trigger pulses of microbial respiration at land-water-interfaces. The regulation of discharge variability is therefore proposed to affect the respiration balance of these sites. In this study, I assessed the impact of discharge regulation on microbial respiration associated to surface sediments at a land-water-interface of the river Spree. I developed a theoretical model, based on empirical respiration data, to estimate the two-month total respiration at the study site for three discharge scenarios. The real scenario represented the actual discharge at the study site, which was regulated by the Spremberg reservoir dam. In the unregulated scenario, the regulating effect by the dam was excluded. In the extremely regulated scenario, a hypothetical constant discharge was modeled. For each scenario, the daily discharge, the corresponding flooded areas, the extent of dry or rewetted areas, and the durations of flooding or rewetting by rain at the study site were determined. Microbial respiration rates associated to surface sediments were measured with a respirometer under flooded, dry, and rewetted conditions. The model applied these rates to the respective flooded, dry or rewetted areas of the study site, to calculate the daily areal respiration. In all sediments from the land-water-interface, a distinctive respiration pulse was measured on the first day of flooding, and higher respiration rates under flooded than under dry conditions. The discharge of the unregulated scenario was characterized by a higher variability and larger flow volume than the regulated real scenario. Due to the higher total discharge, larger areas were flooded in the unregulated scenario, the total respiration from sediments under long-term flooded conditions was therefore higher. Moreover, the daily extent of flooded areas fluctuated more strongly, hence more short-term respiration pulses upon flooding were triggered than in the real regulated scenario. The calculated total two-month respiration of the unregulated scenario exceeded that of the regulated real scenario by almost 14 %. These results suggest that discharge regulation can have a considerable negative impact on sediment-associated microbial respiration at land-water-interfaces.",,"Krüger, Simone",2015,,,OPUS4-4049,Bachelorarbeit
Nitrogen fixation in two polymictic lakes,,"The ability to fix molecular nitrogen is considered to be a competitive advantage of Nostocales to overcome periods of nitrogen shortage but it is unclear to what extend these cyanobacteria import nitrogen into freshwaters and if they are able to compensate the efforts of reducing anthropogenic nitrogen input. We studied nitrogen fixation, cyanobacterial biovolume and species composition and abiotic parameters in two polymictic lakes (Germany) over three years. Although Nostocales were present from April to November N2-fixation was found only from June/July to September. In the summer months, it amounted up to 40 mgN m-²d-¹ or up to 500 mgN m-²d-¹ resulting in rather low annual N-inputs between 0.1 and 8 gN m-²a-¹. We found a high variation in N2-fixation rates between the two lakes and the years, which could neither be explained by total Nostocales biovolume nor heterocyte numbers. N2-fixation rates measured in the field will be analyzed on Nostocales species level, be compared to those of laboratory cultures and be discussed in the context of possible phosphorus or light limitation of Nostocales.",,"Rücker, Jacqueline; Knie, Matthias; Nixdorf, Brigitte; Kolzau, Sebastian; Voss, Maren; Wiedner, Claudia",2015,,,OPUS4-3708,Konferenzveröffentlichung
A Simulation analysis to improve the dielectric strength inside High Voltage Vacuum Interrupters,,"Vacuum circuit breakers are expected to be one of the possible alternatives for SF6 circuit breakers in transmission voltages up to 230kV because of the excellent insulation as well as environmental friendly characteristics of vacuum. But for higher voltages, maintaining the electrical insulation inside and outside the interrupter tube is very important and becoming a challenge for the design engineers. Normally a vacuum interrupter consists of metal shields sandwiched between the ceramic insulator blocks inside the tube. The primary purpose of these metal shields is to protect the insulator walls by avoiding metal vapor deposition during the arcing process. On the other hand, these metal shields also influence the electric field distribution inside the interrupter tube. The presence of the metal shields may reduce the dielectric strength of the interrupter tube if proper measures are not taken. This research is devoted to provide the information about the possible areas inside and outside the interrupter tube that are considered as critical in terms of dielectric strength because of the presence of metal shields. Possible solutions are also given in this thesis to overcome the high field stress in these critical areas with the help of 2D simulations that are simulated in ANSYS Maxwell. The critical areas and their respective solutions presented in this work are (1) unidentified edges outside the interrupter tube which are formed by the metal shields that are inserted between the ceramic blocks. These edges, at high field stress, may act as a source of discharges between the interrupter tube and the outer insulator. This problem can be reduced by the combination of using a pressurized insulating gas (which is in this case N2) between interrupter tube and outer insulator and by extending the unidentified edges and covering them with field grading rings which are conductive in nature. (2) Triple junctions (Vacuum-Ceramic-Metal shield) are the sources of high field stress inside the interrupter tube and are considered as a primary source of Secondary Electron Emission Avalanche that takes place on the (3) ceramic surface. The triple junction emissions can be avoided by properly designing the insulator geometry at point of contact with the metal shield. In addition, inserting metal parts of certain depth at the both ends of the ceramic insulators can also reduce the field stress at the triple junctions and avoid surface flashovers on the ceramic surface. (4) The gap between the metal shield and the contact rod is also considered to be a critical area which can be highly stressed (field) if the geometry of metal shield curvature is not properly designed. Various metal shield curvatures are proposed and simulated and an optimum geometry is suggested that reduces the electric field stress between the metal shield and contact rod. Using this optimized metal shield curvature, the diameter of the interrupter tube can be reduced considerably which in turn reduces the size of the interrupter tube.",,"Venna, Karthik Reddy",2015,,,OPUS4-3355,Dissertation
Comparison of switching behaviours between vacuum and SF6 technologies at 145kV network,,"This PhD project started from one basic question: whether vacuum technology can be applied to 145kV electrical power system networks as a potential substitution to SF6 technology which has been utilised for decades of practice, due to environment and economic concerns. Possible threats and challenges, which might cause problems for the proposed replacement, are identified mainly in three areas: (1) small inductive current switching, (2) capacitive load current switching and (3) short-line fault switching. Three circuit-breaker programming models, therefore, have been developed based on statistic data provided by breaker manufactures: (1) a maximum di/dt fixed model which has been utilised for small inductive current switching tests and capacitive load current de-energising tests; (2) a dynamic di/dt model adopting from Mayr's classic arc model for SF6 circuit-breakers which has been utilised for short-line fault tests; and (3) a current making model for capacitive load current energising tests. In a general conclusion, vacuum technology shows its superiority in most of the switching duties although in some rare cases, SF6 technology still stands a chance to break it even. But if we take the environment and economic factors into consideration, vacuum is definitely worth investigating in the future market.",,"Xu, Ruoyu",2015,,,OPUS4-3669,Dissertation
Concept analysis for High-Voltage Direct-Current circuit breakers for application in a network of HVDC transmission,,"For several decades HVDC technology was used primarily for point-to-point bulk power transmission. Although multiterminal HVDC systems are very few in number, it is expected that multiple HVDC links may be interconnected into HVDC transmission grid. Since every meshed grid requires reliable protection solution, an HVDC circuit breaker must be developed and introduced. This thesis focuses on the performance evaluation of different HVDC circuit breaker concepts. The performance evaluation study is carried out by means of numerical simulations. The obtained quantitative results describe capabilities and limitations of different HVDC circuit breaker concepts as well as the reaction of HVDC network on switching operations. Different converter protection measures and in particular application of fault current limiter were considered, too. Based on the research findings, a number of recommendations for HVDC circuit breaker development are given and suggestions for further research activities are presented.",,"Bonkarev, Maxim",2015,,,OPUS4-3545,Dissertation
Spatial variability and germination potential of cyanobacterial akinetes in sediments of deep dimictic lakes,,"Nostocales form thick-walled, resting cells (akinetes) for overwintering in lake sediments of Central Europe. The pelagic Nostocales population recruits after the germination of akinetes, which mainly takes place in the spring with increasing temperatures and light intensities. The study aimed to i) characterize the sediment surfaces inhabited by viable akinetes that potentially contribute to the formation of a pelagic population, and ii) estimate the inoculum size of the available sedimentary akinete pool. We investigated the horizontal distribution of akinetes in sediments and the seasonal course of light and temperature in two deep dimictic lakes (Lake Stechlinsee, max. depth 69 m and Lake Scharmützelsee, max. depth 29.5 m; NE Germany). The akinete pool was calculated and the potential inoculum was estimated using assumed light and temperature data for akinete germination. The akinete abundance in sediments depended on the basin morphometry and increased with water depth. Only a small proportion of the viable akinete pool in shallow water areas contributed as inoculum to pelagic population. The potential inoculum size in Lake Scharmützelsee was larger than in Lake Stechlinsee.",,"Ramm, Jessica",2015,,,OPUS4-4155,Konferenzveröffentlichung
"Screening Intangible Heritage : media, heritage and representation: the case of Kutiyattam Sanskrit Theatre, India",,"This research investigates the role of audio-visual media in the representation of intangible cultural heritage and provides a theoretically and empirically grounded concept of the interrelation of media, ICH and representation. It identifies both the potentials and risks involved in media representation, as well as responding to the question regarding how audio-visual representations can foster the safeguarding of ICH, aiming at its sustained transmission and recreation. The study conceptualizes representation as a process in which meaning is produced and negotiated. It refers to discourse in Social/Cultural Anthropology, Heritage Studies and Cultural Studies, particularly making use of the circuit of culture model, Hall's encoding/decoding model and Assmann's concept of memory. As ICH is culturally contextualized, the analysis focuses on one specific heritage manifestation: the Kutiyattam Sanskrit theatre. It explores in detail Kutiyattam's history, identity, performance practice and transformation, including after UNESCO's proclamation. It analyses the processes and conditions of production, encoding, circulation, reception, utilization and regulation of audio-visual representation and demonstrates the extent to which these dynamic and manifold reciprocal processes influence Kutiyattam practices and practitioners. In the form of a thick description, the study exemplifies that media and modern technologies foster continuity in practice, revitalization, valorization and self-assertion, that they enable education, research, promotion and dissemination of ICH, and contribute to identity construction and the (re)creation of communities. It shows that audio-visual representations - when produced in collaboration with the practicing communities, thereby facilitating culture-specific coding and community use - constitute significant vehicles within safeguarding measures. Differentiating between horizontal and vertical transmission of ICH as well as micro and macro level consumption, the study further identifies numerous challenges involved in the mediatization and digitization of ICH. It addresses issues of access, participation, appropriation and intellectual property and the conflict-ridden processes of homogenization, fragmentation, commercialization and popularization, among others. It argues that rather than being innocent and neutral reflections of cultural practices, audio-visual representations are actively involved in meaning making and knowledge constitution processes and deeply enmeshed in power. It proves that representations shape memory, cultural identity and history and exercise influence on cultural expressions and communities. The study concludes with the provision of general recommendations, giving guidance regarding the utilization of media as well as the production, consumption and regulation of media work, targeting heritage professionals and media professionals alike.",,"Erlewein, Shina-Nancy",2015,,,OPUS4-3598,Dissertation
Luminescence investigation of bulk solar silicon and silicon thin films on glass substrate,,"The aim of this work is to study the optical properties of crystal defects in multicrystalline solar silicon and poly-/microcrystalline silicon thin films on glass substrate. First a setup for photoluminescence imaging on multicrystalline silicon solar wafers was developed. This system is suitable for detecting band-to-band luminescence as well as defect-related luminescence at room temperature on large-scale wafers at different stages of their processing. Spectroscopic photoluminescence investigations of multicrystalline silicon solar wafers indicated a new intense luminescence line at &#8776; 0.91 eV at room temperature. The origin of this line is probably found in a specific grain boundary. Furthermore, luminescence in the region of 0.8 eV was investigated in detail, and it was found that probably oxygen is responsible for a peak at 0.77 eV at 80 K. Electroluminescence investigations at room temperature at both materials exhibit extended defect structures such as grain boundaries. Furthermore, it can be concluded that electroluminescence imaging in reverse bias mode indicate on serious breakdown points in solar cells, which can lead to destruction of solar cells and modules. By comparing defect-related and reverse bias electroluminescence images, a difference in the spatial distribution of defects emitting D1 radiation and defects emitting light under reverse bias beyond -12 V is detectable. In addition, there seems to be a correlation in the distribution of non-doping impurities and photoluminescence. Concerning this, vertical slabs of two silicon blocks were examined by means of Fourier-transform infrared spectroscopy and photoluminescence. A correlation of the distributions of interstitial oxygen and the band-to-band luminescence profiles could be found. Additionally, a correlation between D3/D4 luminescence profile and nitrogen distribution in the blocks was observed. Finally, the growth process, particularly the transition from amorphous to microcrystalline silicon by PECVD, was studied by combined photoluminescence and Raman investigations. Formation of silicon nano-grains was detected by means of photoluminescence and Raman spectroscopy.",,"Mankovics, Daniel",2015,,,OPUS4-3519,Dissertation
Investigation of particular crystal defects in solar silicon materials using electron beam techniques,,"The aim of this work is to describe and explain the properties of defects in multicrystalline (mc) and thin-film solar silicon (Si). For this reason, investigations with scanning electron microscope methods were performed, namely cathodoluminescence (CL), electron beam induced current (EBIC), electron backscatter diffraction (EBSD) and transmission electron microscopy (TEM). Additionally, photoluminescence (PL) and reverse-biased electro luminescence (ReBEL) measurements were also conducted. Through correlation of PL, ReBEL and EBIC, it was possible to localize breakdown sites at mc-Si solar cells. Problems that occurred during the thin-film EBIC investigations could be demonstrated and explained. For the first time cross sectional EBIC investigations could be performed on thin-film silicon tandem cells. At mc-Si, it was possible to observe the oxygen related P-line next to the common D1-line luminescence at 10 K clearly distinguishable from each other at once. Furthermore, a hitherto not comprehensively discussed intense luminescence line at 0.93 eV could be described in detail. Through correlation of PL, CL, EBIC, EBSD, and TEM measurements, the origin of the now named Di luminescence at 0.93 eV is postulated to be in connection with Frank partial dislocations, with two energetic levels inside the band gap, one at 112±9 meV below the conduction band and the other at 93±10 meV above the valence band. Finally, it was attempted to explain the behavior of twin boundaries at temperatures below 30 K, where these show an enhanced collection efficiency in comparison to the surrounding grains. An alteration of the local ""freeze out"" temperature, possibly by a local band gap narrowing, is suggested as a reason. Another conceivable explanation is a breakdown of the diode potential at the grains.",,"Krause, Christoph",2015,,,OPUS4-3484,Dissertation
"The effects of habitat heterogeneity and human influences on the diversity, abundance, and distribution of large mammals: the case of Deng Deng National Park, Cameroon",,"Large mammals constitute an integral part of biological resources, and hence fundamental elements in many ecosystems. In view of the roles played by habitats and humans in structuring large mammal populations, research was conducted in the Deng Deng National Park, with the aim to identify and characterize the spatial and temporal patterns of habitats, determine the relationship between habitat heterogeneity and mammal abundance and also to investigate the types and extent of human pressure on various large mammal species in the park. Distance sampling technique and kilometric index analyses approaches were applied to determine species presence, frequency and abundance, with dung, nests, and tracks used as proxy for species presence. Using a spatio-temporal analysis approach in Geographic Information System, species distribution was analyzed. Small and medium sized duikers, red river hog and gorilla were most frequently encountered. Important is the record of elephant for the first time in the park, emphasizing the importance of the park for large mammal conservation. Diverse land cover types that constitute habitats for flora and fauna were distinguished and characterized as dense forest, mature secondary forest, young secondary forest, tree and grassland savanna, settlement and degraded areas, and water bodies. Area, mean patch size, shape, density and richness metrics of these land cover types varied, emphasizing the heterogeneity of the park landscape. No significant differences (0.2 &#8804; p &#8805; 0.8) were observed in species abundance due to diverse habitat characteristics in the park. Species exhibited generalist habits with preference mostly for the dense and mature secondary forest habitat types. Temporal pattern over a 23 years' time lag projected a 6.19 % increase in dense forest cover, suggesting future shelter opportunities for large mammals in the park. The park is experiencing threats that are changing the physical environment in simple and reversible manner but also threats that have changed the parks environment in permanent ways; all from impacts of adjacent human settlements and development activities. Generally, species abundance was significantly high (p = 0.03) in habitats where threats encounter rates were low, and low in habitats affected by high human activity; a clear indication that these activities have eventually created depressing effects on the habitats of large mammal species in the park. Actions aimed to limit human activities around the park, and aiming to sustain the large mammals and their habitats, especially within the hotspots identified in this study, are therefore proposed to ensure a more sustainable future for large mammals in the Deng Deng National Park.",,"Diangha, Mercy Nambu",2015,,,OPUS4-3571,Dissertation
Model coupling in hydroinformatics systems through the use of autonomous tensor objects,,"There is an increased focus on interdisciplinary research in hydroinformatic related projects for applications such as integrated water resources management, climate change modelling, etc. The solution of common problems in interdisciplinary projects requires the integration of hydroinformatic models into hydroinformatic systems by coupling of models, enabling them to efficiently share and exchange information amongst themselves. Coupling of models is a complex task and involves various challenges. Such challenges arise due to factors such as models required to be coupled together lacking coupling capabilities, different models having different internal data formats, lack of a coupling mechanism, etc. From the perspective of physics, different models may use different discretisations in space and time, operate on different scales in space and time, etc. A model coupling concept using a coupling broker, that is independent from the coupled models, has been developed in this work and been implemented as a prototype for a software framework for coupling hydroinformatic models. It is based on the approach of tensor objects and the ideas of the OpenMI standard for model coupling. Tensor objects are a complete representation of physical state variables including dimensions, units, values, coordinate systems, geometry, topology and metadata. They are autonomous entities that can adapt themselves to the requirements of coupled models through operations such as scaling, mapping, interpolation in space and time, etc. The central entity in coupling is the Tensor Exchange Server, which acts as the coupling broker. It is responsible for defining the coupling mechanism, brokering the communication between the models and adapting the information to the requirements of the coupled models by taking advantage of the functionality provided by tensor objects. By fulfilling these roles in coupling, the coupling broker concept goes one step further than tools such as the OpenMI standard and facilitates the task of coupling models since each coupled model doesn't individually need to be adapted to be able to perform these tasks on its own. The usefulness of the coupling broker concept for coupling models is demonstrated with the help of three application examples: firstly, a subsurface-flow model coupled with a model simulating metabolism in the hyporheic zone, secondly, a subsurface-flow model coupled with a surface-flow model and finally, an information management system presenting the results of a hydrodynamic simulation of a section of the river Rhine. These examples demonstrate the extensibility and flexibility of the presented coupling concept, which can be used to couple multiple hydroinformatic models in hydroinformatic systems.",,"Notay, Kunwar Vikramjeet Singh",2015,,,OPUS4-3618,Dissertation
A reflection on methodological approaches to assessing and implementing social sustainability in historical public spaces,,"In this paper, through a literature review, I clarify the meaning of public space and reflect on theoretical approaches to and methods of assessing the ability of historic public spaces to enhance social sustainability. I explain how the definition of public space and approaches to urban planning share concepts with social sustainability. Finally, reflecting on examples of empirical research that attempt to link physical and social components of public spaces, I point out the methodological strengths and weaknesses in the field.",,"Yadollahi, Solmaz",2015,10.1515/9783110415278-014,,OPUS4-4902,Teil eines Buches
Study on the temperature effect on lap shear adhesive joints in lightweight steel construction,,"In line with the developments in steel industry, the methods of joining steel members have been developed; therefore, the configuration of functional connections with economic and partly-aesthetic advantages has become possible by the use of the known joining methods, which are bolts, rivets and welding. However, these joining methods do not accompany the further developments and requirements needed to construct lightweight connections or to join dissimilar materials or composite constructions. Moreover, the traditional joining methods do not fulfill the increased requirements of the aesthetics of the joints. In the field of steel constructions, structural engineers might use the bonding technique as an alternative method to join the lightweight steel members or as a helpful mean in the bolted or riveted joints in heavyweight steel structures. Despite the advantages of the adhesive bonding technique, the structural designers in the field of steel constructions are still not able to use it in their practical applications because of the doubts regarding the verifiability of bonded steel joints. This is mainly because of the lack of standards for verifying such joints in steel constructions. To facilitate using this technique in steel constructions, hard efforts have to be performed in order to find out the methods of verifications of bonded steel joints. This starts with understanding the behaviour of the adhesive materials as well as their cohesion ability to the steel surfaces over the whole lifetime of the structure and under all possible loading and environmental conditions. Afterward, the mechanical properties of the adhesives have to be presented by their reliable values that take into account all factors and conditions to which the bonded joint is subjected. These values have to be based on the reliability methods and consequently they are guaranteed for the intended lifetime of the designed structure. It is well known that the adhesives, being viscoelastic materials, are very sensitive to several factors such as the environmental effects, mainly temperature and humidity, and the long-term loading. The loss of strength and durability of adhesives materials, due to the mentioned factors, is an essential aspect that has to be determined and to be taken into account of the structural designers during the design process. For example, it is generally proven that the increase of temperature causes a decrease in the elastic (E) and (G) moduli, cohesive and adhesive forces within the joint and maximum stresses which can be carried by the joint. However, there is still a huge lack in describing the degradations of the mechanical properties quantitatively. Similarly, the failure in the adhesives, loaded for long time by a constant stress even less than their short-term strengths, is probable due to the well-known rheological phenomenon of viscoelastic materials which is the creep phenomenon. Moreover, the adhesives will creep at high temperatures faster; hence the failure will happen in a shorter time. Describing the long-term behaviour of the structural adhesives is still modest; therefore, the time-to-failure of bonded steel joints under long-term loading cannot be exactly predicted. This is an essential issue has to be dealt with to fulfill the requirements of employing the adhesive bonding technique in the structural fields including the steel constructions. The efficiency of using adhesive-bonded joints in steel constructions is higher when the adhesives in these joints are loaded in shear. In such shear joints, the lightweight steel members (adherends) are likely to yield before the break within the adhesive layer happens, especially when large bonded areas are used because the developed shear stresses over the most of these areas will be very small. This thesis deals with the temperature influence on the behaviour of two adhesive systems (acrylic and epoxy) and on the capacities of adhesively bonded lap shear joints. The temperature influence is quantitatively described for short-term loading over a service range of temperature from -20 °C to +40 °C. The quantitative description is done by proposing the partial factors and the conversion factors that take the temperature effect into account. This influence is also dealt with for long-term loading to describe the shear creep behaviour of the adhesive materials used. Consequently, the time-to-failure of the bonded lap shear joints due to the creep phenomenon of the adhesives under three applied stresses at room temperature is predicted. Moreover, the estimation of time-to-failure is extended to be used for other shear stress levels. The temperature influence as well as the efficiency of using adhesive-bonded joints in lightweight galvanized steel constructions is also illustrated by giving a practical example of strengthening cold-formed ""C"" section girders. Comparisons between the two adhesive systems for all cases are given.",,"Sahellie, Samer",2015,,,OPUS4-3515,Dissertation
Study of crystallography and erosion behavior of single and multilayer coatings used for applications in aero engines,,"Erosion of aero-engine components has been identified as a serious problem since the World War II. During this time various attempts have been made to study this phenomenon in order to improve the life and performance of the used components. Flights in particulate environments led to the drastic degradation of the performance due to blunting of blade edges, reduction of chord and increase of tip clearance. Measures like coating of blades and high efficiency filters have been introduced in order to protect the aero-engine components from wear in dusty environments. In the present work an effort has been made in order to deposit various single and multilayer coatings for the erosion protection of Inconel718 alloy used as the substrate material. Inconel718 finds its applications in high pressure compressors within gas turbines. To deposit the various coatings onto the substrate material the Direct Current (DC) Method has been used as a Physical Vaporization Deposition technique. The architecture of the investigated coatings is on one side a single layer TiN coating and on the other side multilayer Cr/CrN, Ti/CrN and TiN/CrN coatings as well. The experimental results show that bilayer Cr/CrN multilayer coatings possess a variation in mechanical properties with the change in bilayer period. Additional adhesion tests show various spallation mechanisms which are related to the coating architecture. Process parameters used during the coating process had an influence on the coating growth. The growth of coatings as in form of a V-structure results in low adhesion between the coating and the substrate or the previous coating layer. Another change in the coating structure is obtained by changing metallic or ceramic layer between CrN layers. The presence of coating defects, like droplets, on the coating surface acts as voids within the coating structure decreasing the structural integrity of the coatings. The conduction of a phase analysis of Cr/CrN multilayer developed the presence of a mixture of fcc-CrN, hcp-Cr2N and bcc-Cr phases. A variation in the phase formation is found to be dependent on the bilayer period of the coatings. A complex XPS analysis and a related thermodynamic study indicate that the variation in the binding energies and thermodynamic stability of the CrN and Cr2N phases are responsible for their stable formation during the coating deposition. TiN single layer coatings showed the formation of a single phase fcc-TiN. The presence of Cr2N, Cr2Ti, TixNy phases is found during the deposition of Ti/CrN and TiN/CrN coatings. An additional Scherrer analysis to evaluate the determination of crystal size pointed out the presence of nano-crystals of various phases within the coatings. Stress analysis of the tested Cr/CrN coatings showed compressive stresses within the coatings, respectively. In this case only slight differences in stress values are observed for Cr1/CrN3 and Cr0.25/CrN3.75 coatings. Erosion tests of Cr/CrN coatings showed erosion protection at shallow incidence angles (30°) as compared to uncoated Inconel718 alloy. In contrast, no erosion protection is obtained during the erosion at oblique angles. Crack deflection at the metal-ceramic interface, shearing of columns, internal distortion of CrN layer, radial and cone cracking, step shear, inter- and intra-columnar crack propagation are reported as some of the processes occurring during the erosion process. The presence of micro droplets is reported to be one of the major causes of low adhesion between the coating and substrate or structural weakness of coating, which provokes a rapid removal of the coating. Within the last section of the present thesis the correlation between various models (proposed through contact mechanics) and erosion rate is studied. It is found that for the single layer and multilayer coatings a low correlation between H3/E2 and erosion rate exists. A study of the ratio between elastic modulus of coating to elastic modulus of substrate (Ef/Es) in order to describe the erosion mechanism in a coating show non-conformance of the results as proposed by contact mechanic theories. A difference in the elastic modulus of consecutive coating layers (E1-E2) showed that no correlation can be found for the coatings during erosion at 30° and 90°.",,"Naveed, Muhammad",2015,,,OPUS4-3562,Dissertation
Heritage and aesthetic displeasure: the value of aesthetic discomfort exemplified through three case studies,,"The World Heritage List, created in 1972 by the Convention Concerning the Protection of the World's Cultural and Natural Heritage, exhibits few cultural sites younger than the signing of the convention, as well as everyday structures which comprise the contemporary urban life. This idea of heritage as something related to the ancient not only is manifested in the international sphere but has also permeated national views, weakening awareness for discreet heritage, which compete with designs from famous architects or monumental structures, giving the impression that grandeur and looks are highly coveted. This does not only discard relevant events of the mid-late 20th century attached to smaller constructions that had impacts on different cultures, but also integral components of urban fabric. Furthermore, these approaches towards heritage relevance resonate within the local populations, who, taking as examples how heritage is treated and approached in an international context, tend to overlook structures that are considered aesthetically displeasing because they do not adhere to this traditional scheme seen in the heritage field. From here extends the idea of analyzing case studies that fall within overlooked heritage from a new angle: one of valuating aesthetic displeasure. The thesis will focus on individual and serial constructions of the 20th century commonly seen as displeasing due to their typologies and styles but also due to their formal characteristics, redirecting the attention from those considered aesthetically pleasing and grandiose towards otherwise ignored built heritage. Additionally, it will address the perceptions of such structures in the context of the international heritage and conservation spheres, to present how these structures are currently not fully appreciated within the traditional idea of heritage due to their looks and commonality. This approach does in fact overlook, and even relegate, those buildings that do not fit into the preconceived idea of aesthetics, denying the opportunity to explore and find their potential for heritage value.",,"Starokozhev, Yanis Alexis Diaz",2015,,,OPUS4-4238,Masterarbeit / Diplomarbeit
Effect of lakeshore modification on structure and secondary production of macroinvertebrates in a large temperate lowland lake of Northeast Germany,,"Many lake water bodies not attained the goal of the European Water Framework Directive (WFD) to achieve a good ecological state by 2015. This is, among other things, because the assessment and improvement of hydromorphological conditions of lakeshores has been neglected as an important component ensuring the ecological integrity of lake ecosystems. In recent years, macroinvertebrates were emphasized to be useful indicators for the assessment of lakeshore hydromorphology. Hence, in Europe macroinvertebrate-based assessment methods were developed to evaluate the hydromorphological conditions of lakeshores. In this thesis, some of the uncertainties and missing aspects of existing macroinvertebrate-based assessment methods were addressed. The results were obtained by sampling macroinvertebrates and macrophytes at natural shores and at shores modified by marinas and beaches in three depth zones between April and November 2011 in a large lowland lake (Lake Scharmützelsee, Germany). Firstly, I clarified that upper littoral macroinvertebrates should be used for assessing the hydromorphology of lakeshores. It was shown that the effect of lakeshore modification on macroinvertebrate diversity and community composition was most pronounced in the upper littoral and decreased to the profundal zone. Secondly, I demonstrated that a single seasonal sampling is sufficient to capture the compositional differences of macroinvertebrate communities associated with human lakeshore modification. Seasonal effects on upper littoral macroinvertebrate diversity and composition were less important than shore type in comparison with the middle littoral and profundal zone. Thirdly, upper littoral macrophyte communities were also affected by lakeshore modification and at the same time the most important variable structuring macroinvertebrate communities. Hence, the effects of different shore types on macrophytes were transferred to macroinvertebrates, but artificial substrates were also able to partly substitute macrophyte habitats as it was shown for the studied marinas. Since lakeshore modification affected macrophytes slightly differently than macroinvertebrates, macrophytes should be considered as an additional component in lakeshore assessment. Finally, secondary production as proxy to determine the effect of lakeshore modification on the functioning of macroinvertebrates was estimated. Estimation of secondary production requires the determination of biomass. Biomass was indirectly determined by using length-mass regressions established for macroinvertebrates from temperate lakes of the central European lowland. The result showed that total secondary production and secondary production of native taxa in the upper littoral was substantially lower at the studied beaches compared to natural sites. In contrast, upper littoral secondary production at marinas did not differ to natural sites, but secondary production of non-native taxa was significantly higher at marinas. No effects of lakeshore modification on secondary production were found with increasing depth. Different scenarios based on upscaling of site-specific production to whole lake ecosystem level gave evidence that the observed local impacts of lakeshore modification can translate into alterations of the functioning of macroinvertebrates at whole lake ecosystem level. In addition, it was emphasized that secondary production as a functional measure is more sensitive in detecting hydromorphological alterations than the structural measures diversity or biomass. Secondary production should therefore be included in existing lakeshore assessment methods. In order to obtain a comprehensive overview about the changes in the functioning of macroinvertebrates following lakeshore modification, it is recommended to consider not only total secondary production but also secondary production of functional groups. With these results, this thesis contributes to the mechanistic understanding of the effect of lakeshore modification on the functioning of macroinvertebrates and the consequences for the functioning of the whole lake ecosystem. The newly generated knowledge helps to optimize the development of successful lakeshore assessment tools and identification of management measures.",,"Pätzig, Marlene",2015,,,OPUS4-3644,Dissertation
Microbial nitrogen transformations in constructed wetlands treating contaminated groundwater,,"Groundwater is the main source for potable water and domestic use in numerous countries around the world. However, water quality can be affected by pollution, which influences the natural environment and human health. One of the widespread pollutants in water is ammonia which is toxic to fish and causes eutrophication of lakes and wetlands. Constructed wetlands are promising in situ water treatment methods thanks to enhanced microbial growth within the plants' rhizospheres, which creates an effective contaminant degradation zone. The ammonia in constructed wetlands can be removed either via total nitrification with further denitrification or partial nitrification coupled with anaerobic ammonium oxidation (anammox). However, so far, the role of anammox in constructed wetlands as well as its correlation with other nitrogen transformations remains unclear. The quantification of nitrogen turnover processes in constructed wetlands is difficult due to the complexity of the wetland systems. Accordingly, the main aim of this research is to investigate pathways of ammonium removal in constructed wetlands treating contaminated groundwater. For this, several approaches were applied: a) physico-chemical parameters measurements; b) investigations of nitrogen stable isotope fractionation; c) stable isotope labelling approach; d) molecular biological methods. Also, seasonal and spatial variations in nitrogen transformations in several types of constructed wetlands (unplanted horizontal subsurface flow, planted horizontal subsurface flow, and floating plant root mat) were investigated. The application of the stable isotope approach combined with common physico-chemical investigations enabled us to identify key factors influencing efficiency of nitrogen removal in constructed wetlands, which was the plant presence as substrate for attachment and growth of microorganisms. Ammonium removal efficiencies were not different between investigated seasons (spring, summer, and autumn), what could be explained by the fact that throughout all investigated seasons the air temperature remained high (above 10°C). While plant uptake accounted for significant part of ammonium removal during spring and summer in planted constructed wetlands, isotope fractionation patterns revealed that nitrification-denitrification were prevailing processes in planted constructed wetlands throughout the year, occurring in a linear way along the flow path, and not depending on depth in the root zone. The research results also illustrated that in the planted horizontal subsurface flow constructed wetland, the functional genes of the nitrogen cycle were evenly distributed in a linear way along the flow path with prevalence at the superficial points. The same trend was observed for the nitrification and denitrification turnover rates using the isotope labeling techniques. Significant nitrate consumption under aerobic conditions diminishes nitrification rates and should therefore be taken into account when estimating nitrification turnover rates. This nitrate consumption was due to aerobic denitrification, the rate of which was comparable to that for anaerobic denitrification. Consequently, denitrification should not be considered as an exclusively anaerobic process. Phylogenetic analysis of hydrazine synthase (hzsA) gene clones indicated the presence of Brocadia and Kuenenia anammox species in the constructed wetland. Although anammox bacteria were detected by molecular methods, anammox activity could not be measured and hence this process appears to be of low importance in nitrogen transformations in these freshwater ecosystems. In conclusion, this research demonstrated that combination of physico-chemical measurements with stable isotope and molecular biological approaches is an effective tool for investigation of nitrogen transforming processes in constructed wetlands. Such information is not only valuable for understanding of the processes ongoing inside these wastewater treatment facilities but also necessary for further technological improvement of constructed wetlands.",,"Coban, Oksana",2015,,,OPUS4-3500,Dissertation
SCA resistent implementation of the Montgomery kP-algorithm,,"Mathematically, cryptographic approaches are secure. This means that the time an attacker needs for finding the secret by brute forcing these approaches is about the time of the existence of our world. Practically, an algorithm implemented in hardware is a device that generates a lot of additional data during the calculation process. Its power consumption, electromagnetic radiation, etc. can be measured, saved and analysed for key extraction. Such attacks are called side channel analysis attacks and are significant threats when applying cryptographic algorithms. By considering these attacks when implementing a cryptographic algorithm, it is possible to design an implementation that is more resistant against them. The goal of this thesis was to design a methodology to securely implement the Montgomery kP-operation using an IHP implementation as a starting point. In addition, the area and energy consumption of the secure Montgomery kP-multiplier should still be highly efficient. The resistance against power analysis attacks of two different IHP ECC implementations was analysed in this thesis. A horizontal power analysis attack using the difference-of-means test was performed with the goal of finding potential leakage sources exploited in side channel analysis attacks, i.e. finding the reasons of a correct extraction of the cryptographic key. For both analysed ECC designs, four key candidates were extracted with a correctness of 90% or more. Through analysis of the implemented Montgomery kP-algorithm's functionality and its power consumption, it was established that the algorithm's operation execution flow was the main cause of the implementations' vulnerability. Thus, a design methodology consisting in changing the Montgomery kP-algorithm operation flow was developed. As a result, the re-designed implementations do not deliver any correctly extracted key candidates whenever the difference-of-means test is performed on them. These re-designs implied an increase on the chip area by about 5% for each implementation. The execution time needed for performing a complete kP-operation was reduced for both designs. Thereby one implementation's execution time was reduced by 12% in comparison to its original version and even though its power consumption was increased by 9%, its energy consumption per kP-operation was reduced by 4.5%.",,"Alpirez Bock, Estuardo",2015,,,OPUS4-3628,Masterarbeit / Diplomarbeit
Application of ODT to turbulent flow problems,,"The continual optimization process for more efficiency of industrial flows has raised the need for providing deeper understanding of turbulence. These details can be provided by direct numerical simulation (DNS), which is impossible for most flows with current computers. Therefore, progress in optimizing Reynolds averaged Navier-Stokes (RANS) and large eddy simulation (LES) modeling strategies will need to continue. Another ansatz is the reduction to 2D or 1D models to reduce the numerical cost. One dimensional turbulence (ODT) as presented by A. R. Kerstein is a new modeling strategy that reduces the 3D simulation to a 1D line of sight through the flow region. Due to the higher resolution afforded by the 1D model, it is possible to simulate even the smallest scales and to provide insight into turbulence statistics. To assess the advantages and disadvantages of the model, ODT has to be validated against several flows. Within this thesis, ODT is validated against the channel flow, the passive scalar transport and the channel flow with a fluctuating pressure gradient. These flows are simplified test cases for the phenomena present in single-phase industrial flows. ODT produces meaningful results for friction Reynolds numbers up to Re&#964; = 6·10&#8309; and for Prandtl numbers from Pr = 0.025 to 50. Statistics of the wall shear stress are presented and the influence of pressure fluctuations is discussed. Based on these channel results, the non-breaking and breaking jet are simulated. While the former is a simplified case of a free-surface flow, the latter is of primary interest for spray formation and fuel injection. Detailed statistics of the TKE budgets and the breakup are presented. As the last case, the cloud top of a stratocumulus-topped boundary layer (STBL) was simulated. The case combines the interaction of an active and a passive scalar. It further combines the simulation of a stable and an unstable stratified region that suppresses and enhances turbulence respectively. The simulations reproduce the entrainment velocity and generate comparable mean and flux profiles compared to DNSs.",,"Meiselbach, Falko T.",2015,,,OPUS4-3495,Dissertation
The PCP theorem in real number complexity theory,,"In this thesis we consider probabilistically checkable proofs (PCPs) in the model of computation working with real and complex numbers as introduced by Blum, Shub and Smale (the BSS model). Starting point of this thesis is the so-called PCP theorem, a major result in complexity theory. Roughly speaking this theorem says that one can check the correctness of certain proofs of mathematical statements with high probability by only looking at small parts of the proof. PCPs have a natural formulation in the BSS model as well. Considering the importance of the PCP theorem it seems natural to ask whether a similar theorem holds in this model also. The PCP theorem in the Turing model has two qualitatively very different proofs. The original proof by Arora et al. uses mostly algebraic techniques. Later another, combinatorial proof was discovered by Dinur. In this thesis we give two corresponding proofs in the BSS model. Thereby we establish the PCP theorem in the framework of the real numbers as well as in the framework of the complex numbers. The main difficulties occur due to the fact that the structures R and C over which we work are uncountably infinite. For both classical proof techniques partially really new ideas are necessary to apply their structure to the new computational model. Apart from the importance of the PCP theorem it helps to better understand the similarities and differences between both models of computation. We hope that the new ideas we develop may be useful in other contexts as well.",,"Baartse, Willem Martijn",2015,,,OPUS4-3624,Dissertation
Spectroscopic and electrochemical study of TiO&#8322;/Si photocathode,,"Diese Dissertationsschrift beschäftigt sich mit der Atomlagenabscheidung (ALD) dünner TiO&#8322;-Schichten auf p-Typ Silizium, untersucht die elektronischen Eigenschaften der abgeschiedenen Schichten und beschreibt die elektrochemische Charakterisierung von TiO&#8322;/Si-Photoelektroden. Die Abscheidungsparameter, die elektronischen Eigenschaften und die Stabilität der TiO&#8322;/Si-Proben werden miteinander korreliert. Mittels der ALD-Technik wurden TiO&#8322;-Schichten mit zwei verschiedenen Prekursoren (Titan- Isopropoxid und Titan-Methoxid) auf Si-Substraten abgeschieden. Labor- und Synchrotron basierte Röntgen-Spektroskopietechniken wurden benutzt, um die abgeschiedenen Schichten zu charakterisieren. Die Qualität der Schichten wurde dabei mittels Röntgen-Photoelektronenspektroskopie (XPS) beurteilt, wobei die Stöchiometrie, das Ti³&#8314;/Ti&#8308;&#8314;-Verhältnis sowie Defektzustände in den TiO&#8322;-Filmen Kriterien darstellten. Um verschiedene Polymorphe von TiO&#8322; zu erhalten, wurde die Heizmethode der Schichten innerhalb der ALD-Prozedur variiert. Die elektronischen Eigenschaften amorpher und Anatas-TiO&#8322;-Schichten wurden mittels Synchrotronstrahlung bestimmt und mit denen eines TiO&#8322;-Rutil-Einkristalls verglichen. Röntgen- Absorptionsspektroskopie (XAS) und resonante Photoelektronenspektroskopie (res-PES) wurden mit Synchrotronstrahlung durchgeführt. Dabei diente die XAS der Bestimmung der Art des Polymorphen und der elektronischen Struktur der TiO&#8322;-Schichten. Res-PES-Messungen wurden an den O1s- und Ti2p- Kanten durchgeführt, um Auger-Prozesse mit multiplen Loch-Endzuständen sowie polaronische und Ladungstransferzustände zu untersuchen und um die elektronische Bandlücke der TiO&#8322;-Schichten zu bestimmen. Eines der Hauptergebnisse dieser Arbeit stellt die Bestimmung der partiellen Zustandsdichten (pDOS) von Sauerstoff und Titan im Valenz- und Leitungsband dar. In der Analyse der res-PES-Daten wurde die pDOS mit den entsprechenden Bandkantenpositionen kombiniert, um die energetische Lage der Ladungsneutralitätsniveaus (&#8218;Charge neutrality levels') der verschiedenen TiO&#8322;-Polymorphe zu ermitteln. Photoelektrochemische Messungen wurden an unbeschichteten und TiO&#8322;-beschichteten Si- Photoelektroden durchgeführt. Dabei wurde die elektrochemische Performance der Photoelektroden in verschiedenen Elektrolytmedien mit pH-Werten zwischen 1 und 13 untersucht. Die Beschichtung der Si- Oberfläche mit einer dünnen TiO&#8322;-Schicht verbesserte die Performance der Si-Photoelektrode, wobei die Stabilität der Elektrode in allen untersuchten Elektrolytmedien während der gesamten Messdauer von 12 Stunden erhöht wurde. Außerdem wurde festgestellt, dass die TiO&#8322;/Si-Photoelektrode weniger empfindlich auf Änderungen des pH-Wertes reagiert. Die elektrochemischen Ergebnisse werden auf Basis der elektronischen Eigenschaften der TiO&#8322;-Schichten diskutiert. Die durch die spektroskopischen Messungen bestimmte elektronische Bandlücke sowie die photoelektrochemischen Charakterisierungen werden zur Erklärung der Performance und Stabilität der TiO&#8322;/Si-Photoelektroden herangezogen. Die Arbeit adressiert außerdem die Stabilität von mikrostrukturierten Photoelektroden (SiMP), die elektrochemisch präpariert wurden. Zunächst verschlechterte sich die Stabilität der SiMP schneller als bei der planaren Si-Photoelektrode. Jedoch führte die Nutzung einer TiO&#8322;-ALD-Schutzschicht auf der SiMP zu einer besseren Gesamtperformance der SiMP auch im Vergleich zum System TiO&#8322;/ planares Si.",,"Das, Chittaranjan",2015,,,OPUS4-3692,Dissertation
Volunteering as a form of community involvement at UNESCO World Heritage sites. Designing a volunteer programme at the World Heritage site of the Palaces and Parks in Potsdam and Berlin,,"The research introduces volunteering at World Heritage site as a potential civic engagement tool, which can increase communication between heritage property and local community. The first part of the study focuses on the concept of volunteering and on the role it plays in community involvement at World Heritage sites as well as on its benefits for social development in general. The second part of the research intends to give practical recommendation on designing a volunteer program under conditions of the World Heritage site of the Palaces and Parks in Potsdam and Berlin. The author raises a question how a volunteering program can be organized to be effective and at the same time to respond to the UNESCO World Heritage Programme and to the newest UNESCO conservation concepts, such as Historic Urban Landscape approach. The study aims to serve as a practical guide for museums and heritage organisations that intend to improve community involvement in their work.",,"Dontcova, Anna",2015,,,OPUS4-3731,Masterarbeit / Diplomarbeit
A preference-based relevance feedback approach for polyrepresentative multimedia retrieval,,"The search for textual information, e.g., in the form of webpages, is a typical task in modern business and private life. From a user's point of view, the commonly used systems have matured and established common interaction design patterns such as the textual input box that starts virtually every directed search process. In comparison, the search for multimedia documents (e.g., images or videos) is still in its early years. In other words, a pre-dominant search strategy has not yet evolved. That is, directed and exploratory search approaches fight for user acceptance. One further discriminative factor of multimedia information retrieval (MMIR) from traditional text-based information retrieval (IR) is that multimedia documents are not necessarily stored with the help of the same data access paradigm. From a technical point of view, the use of different data access paradigms complicates the retrieval from such collections because the utilized retrieval model has to support these paradigms. As a consequence, the main challenges in MMIR - the retrieval engine and the user interaction -- have to be addressed in a holistic way. A holistic theoretic perspective on MMIR/IR research is taken by principle of polyrepresentation (PoP), which forms one half of the theoretic background of this dissertation aiming at the development of a preference-based approach to interactive MMIR. Roughly speaking, the PoP theorizes that representations describing a document are based on various cognitive processes dealing with it, e.g., a title, its color or shape features, its creator, or its date of creation. This multitude of representations can be fused to form a conjunctive cognitive overlap (CO) in which highly relevant documents are likely to be contained. This explicit recommendation discriminates the PoP from typical feature fusion approaches often used in MMIR. However, the PoP does not answer how a retrieval model has to be implemented in a technical sense which is of interest in the field of computer science. One possibility to implement the PoP are quantum mechanics-inspired IR models such as the commuting quantum query language (CQQL) which is used in this thesis. CQQL is particularly interesting because it integrates data access paradigms used in the fields of DB and IR. In order to respect the dynamic nature of the search process and information need (IN), CQQL allows the personalization of retrieval results using a preference-based relevance feedback (RF) approach called PrefCQQL, which relies on machine-based learning. Unique features of the PrefCQQL approach range from the support of negative query-by-example (QBE) documents at query formulation time as well as during the interactive retrieval process to the formulation of weak preferences between result documents to express gradual levels of relevance. In addition, inductive preferences can be used from query formulation time onward to learn new CQQL queries. In order to evaluate the presented polyrepresentative PrefCQQL approach, two kinds of experiments are conducted: a Cranfield-inspired evaluation of CQQL/PrefCQQL's retrieval effectiveness, which is extended by the utilization of user simulations to better fit the requirements of the evaluation of an adaptive IR system, and a usability study that examines three alternative MMIR system UI prototypes. In order to increase the reproducibility and confirmability of the experiments, the source code to all used programs is made available as a supplement to this dissertation. The mentioned experiments aim at answering two central questions: first, whether the hypotheses of the PoP can be verified in MMIR, and second, whether a usable interactive MMIR system can be built on the basis of the PoP and PrefCQQL? To answer the first question, different matching functions that partly follow the recommendations of the PoP are evaluated with six different test collections in both an non-interactive and interactive QBE scenario. The results of this experiment are ambivalent. In non-interactive MMIR, the experimental data does not provide sufficient justification for the statement that PoP-based matching functions will always surpass single features or other matching functions. For instance, the arithmetic mean, which calculates the average similarity between a query's representations and the documents' representations in the collection, surpasses the conjunction and hence the CO of multiple representations in terms of retrieval effectiveness. Nevertheless, the matching function following the PoP is effectiveness stabler than the best performing single representations per collection. Hence, the CO's retrieval performance is more reliable than the usage of single representations. In contrast, the predictions of the PoP can be verified in the investigated PrefCQQL-based interactive MMIR scenario. However, it is important to note that also the number of available representations has an impact on the retrieval outcome. That is, if too few representations are present in a matching function, the corresponding IN model in PrefCQQL obviously becomes subject to underfitting eventually lowering its retrieval effectiveness. Unfortunately, when the point of sufficient representations to support PrefCQQL is reached could not be revealed in this dissertation. The second question is answered with the help of a prototypical MMIR system: the Pythia system, which serves both as proof of concept of the CQQL and the PrefCQQL approach. Furthermore, the system supports different information seeking strategies and a seamless transition between them in order to support users with different kinds of IN.",,"Zellhöfer, David",2015,,,OPUS4-3521,Dissertation
Statistical analysis of extreme climate events in Brandenburg,,"The main idea of this paper is to evaluate the performance of the fine resolution CLM model in the state of Brandenburg Germany, create a bias correction method and reanalyze the climate signals of the corrected simulations on projections of the 21st century. The bias correction method is a distribution oriented method and the analysis is mainly focused on the extreme events such as 95 and 5 percentile daily temperatures and 95 percentile daily precipitations in a period of 30 years, but also includes seasonal temperature, daily temperature difference and monthly precipitation to demonstrate the effectiveness of the correction method. The results showed that the correction method was very effective on different variables. After correction, the extreme daily temperature bias was reduced from a cold bias of 1-2K to less than 0.1K. The corrected projection simulations suggested that the extreme temperatures were about to increase both in intensity and in frequency. The extreme precipitation after correction was meant to become more severe and frequent as well.",,"An, Ni",2015,,,OPUS4-3611,Dissertation
Time series scenario composition framework in Hydroinformatics Systems,,"Since Z3, the first automatic, programmable and operational computer, emerged in 1941, computers have become an unshakable tool in varieties of engineering researches, studies and applications. In the field of hydroinformatics, there exist a number of tools focusing on data collection and management, data analysis, numerical simulations, model coupling, post-processing, etc. in different time and space scales. However, one crucial process is still missing &#8212; filling the gap between available mass raw data and simulation tools. In this research work, a general software framework for time series scenario composition is proposed to improve this issue. The design of this framework is aimed at facilitating simulation tasks by providing input data sets, e.g. Boundary Conditions (BCs), generated for user-specified what-if scenarios. These scenarios are based on the available raw data of different sources, such as field and laboratory measurements and simulation results. In addition, the framework also monitors the workflow by keeping track of the related metadata to ensure its traceability. This framework is data-driven and semi-automatic. It contains four basic modules: data pre-processing, event identification, process identification, and scenario composition. These modules mainly involve Time Series Knowledge Mining (TSKM), fuzzy logic and Multivariate Adaptive Regression Splines (MARS) to extract features from the collected data and interconnect themselves. The extracted features together with other statistical information form the most fundamental elements, MetaEvents, for scenario composition and further time series generation. The MetaEvents are extracted through semi-automatic steps forming Aspects, Primitive Patterns, Successions, and Events from a set of time series raw data. Furthermore, different state variables are interconnected by the physical relationships derived from process identification. These MetaEvents represent the complementary features and consider identified physical relationships among different state variables from the available time series data of different sources rather than the isolated ones. The composed scenarios can be further converted into a set of time series data as, for example, BCs, to facilitate numerical simulations. A software prototype of this framework was designed and implemented on top of the Java and R software technologies. The prototype together with four prototype application examples containing mathematical function-generated data, artificial model-synthetic hydrological data, and measured hydrological and hydrodynamic data, are used to demonstrate the concept. The results from the application examples present the capability of reproducing similar time series patterns from specific scenarios compared to the original ones as well as the capability of generating artificial time series data from composed scenarios based on the interest of users, such as numerical modelers. In this respect, it demonstrates the concept's capability of answering the impacts from what-if scenarios together with simulation tools. The semi-automatic concept of the prototype also prevents from inappropriate black-box applications and allows the consideration of the knowledge and experiences of domain experts. Overall, the framework is a valuable and progressive step towards holistic hydroinformatics systems in reducing the gap between raw data and simulation tools in an engineering suitable manner.",,"Li, Chi-Yu",2015,,,OPUS4-3365,Dissertation
"Sustainable development of domestic water supply in emerging megacities : the case of the city of Guadalajara, Mexico",,"Water is a primordial resource for the development of urban agglomerations. Today, 50% of the population worldwide is concentrated in urban settlements and 10 - 20% of all worldwide freshwater consumption occurs in the domestic sector (UN: World water development report 3). By 2030, 60% of the world's population will be living in urban settlements (UNESCO), and domestic freshwater consumption will rise by 70% in 2025. Urban areas inflict high pressure on the local and even regional water sources, since the high population density requires large flow volumes in a restricted area, with often competing pressures on the water resource per se as well as for the space needed for water storage or aquifer recharge. This becomes complicated and even critical in areas where natural water availability is already scarce and urban demand is high due to large population sizes. Today 700 million people in 43 countries are living in water stress condition (Human Development Report 2006). Mexico, ranking 88 on a global scale in water availability per capita, is a clear example of this situation, where the most populated urban settlements, such as Mexico City, Monterrey, Guadalajara, Puebla or Queretaro are located in regions which concentrate only 31% of the renewable water of the country (CONAGUA). Thus, the main question arises: How will the urban settlements develop a sustainable water supply now and in the future? The city of Guadalajara, in particular, has seen an extremely fast and chaotic development in the past three decades, where the population of the city increased from 1,354,000 inhabitants in 1970 to 4,064,000 in 2005; by 2020 Guadalajara is expected to overpass the 5 million inhabitants thus becoming a megacity. Nowadays, overall water consumption in the city is about 9.3 m3/sec. and it is estimated to be 10.3 m3/sec by 2030, with Lake Chapala as the main water source, supplying 55% of the water demand. However, Lake Chapala has been confronted with several severe droughts which critically lowered its water table as was the case between 1998 and 2003 and due to its weak equilibrium droughts could be more recurrent in the future. As the water supply of Guadalajara is strongly linked to the faith of Lake Chapala, Guadalajara needs to reduce its pressure on the lake by adopting strategies based on sustainable development. The main goal of this research is to provide governments and decision makers with a robust tool that integrates the most amount of information possible but presents this information in a simple way, offering at the same time the possibility to detect the factors that need to be addressed in order to reach sustainability. The specific aim is to test the use of composite indices (CIs) to the case of the city of Guadalajara in the period of the year 2000 to 2009. CI is a holistic methodology in which independent variables can be aggregated into a single result. CIs thus allow for the comparison between different cases, the integration of qualitative and quantitative variables and the easy use by decision makers. We used 11 carefully selected variables from all three sectors of sustainability, economical, ecological and social, which were first normalized using ranging procedures and process capability indices, and aggregated by using the weighted geometric mean. A set of best strategies Guadalajara should follow are suggested in order to have a sustainable water supply in the future. With this study, we have been able to show that CIs are an effective tool for evaluating sustainability of domestic freshwater supply at local scale. Overall, Guadalajara reached a CI of 0.29 showing, that its domestic water supply is currently not sustainable. It was able to identify the following three main problems: a) lack of wastewater treatment with just less than 3% of the waste water being treated; b) water loss in the distribution system, with 34% of the water extracted being lost at some point in the distribution system (during treatment, in the pipelines and dweller connection to the distribution net); c) water availability, with increased flow volumes of Lake Chapala in the last six years, but only surpassing its natural storage twice (2004 and 2009). Nonetheless, a clear trend of continuous improvement could be seen overall in the past years with a decline in the domestic water consumption per capita to levels comparable to the one in Berlin, as a consequence of people awareness after the several drought Lake Chapala suffered in the beginning of the decade, and an increase in the level of access to piped water and connectivity to the drainage system to 94% of the city's coverage in 2009 (on year 1990, the access to piped water was 89% and the connectivity to the drainage system was 92%).",,"Gómez Jáuregui Abdó, Juan Pablo",2015,,,OPUS4-3607,Dissertation
Comparative STM-based study of thermal evolution of Co and Ni germanide nanostructures on Ge(001),,"Since 1947, when Bardeen and Brattain initiated the era of microelectronics by constructing the first Germanium (Ge) transistor, semiconductors have become the main material platform for advanced integrated circuit (IC) technologies. Later on, given in particular the electrical stability of its native oxide, IC technology shifted from Ge to Silicon (Si) substrates and the dominance of Si-based complementary metal oxide semiconductor (CMOS) microelectronics is today unquestionable. However, as the semiconductor industry is approaching the limits of traditional Si CMOS scaling, the integration of new materials into Si micro- and nano-electronics is required to extend the performance and functionality of future CMOS-based IC technologies. Recently, Ge due to its superior optoelectronic properties and compatibility with conventional Si CMOS technology has re-emerged as an alternative semiconductor material on the mainstream Si technology platform. Many of the Ge integration challenges, such as e.g. doping, epitaxial quality etc., have been recently solved or minimized to an acceptable level. However, the fabrication of low resistance, thermally stable metal/Ge contacts is still one of the main barriers towards the full use of the potential offered by Ge. In particular, the formation of ohmic contacts is relevant for applications where high current densities are of importance (i.p. Ge p-MOSFET and Ge laser applications). Consequently, intensive investigations of metal/Ge contacts are imperative for future applications of Ge. Various metal/Ge contact systems were studied and demonstrated good thermal stability and promising electrical properties. However, given their widespread use in Si CMOS technologies in form of their respective silicides, Co- and Ni-germanides seem to be an obvious choice for electrical contacts in Ge-based devices. Both metal/Ge systems exhibit a complex bulk phase diagrams with a wide range of different physical properties. It is generally acknowledged that the stoichiometric CoGe2 and NiGe phases are best suited for ohmic metal contact formation, mainly due to their low resistivity. It is worth noting that the bulk phase diagram is limited in its use for nanoscience due to an increased surface/volume ratio as well as by the strong nanostructure/substrate interface influence. This PhD thesis sheds light on the formation process at the atomic level of Co and Ni germanide nanostructures on clean, reconstructed Ge(001) substrates. The main part of the presented research is based on in-situ scanning tunneling microscopy (STM) studies on the influence of subsequent, post-evaporation annealings at various temperatures in order to follow and investigate on the nano-scale the structural evolution of a few monolayers of Co and Ni metal (deposited at RT and in UHV conditions) on an atomically clean, reconstructed Ge(001) surface. Furthermore, additional techniques like LEED, (S)TEM-EDX and XPS were used to corroborate and complement the STM derived insights. It was demonstrated that - for both investigated systems - room temperature deposition of a few metal monolayers on clean Ge(001) results in a Volmer Weber growth mode. Starting with annealing treatments at relatively low temperature ranges, the formation of a continuous MetalxGey wetting layer from as-deposited 3D metal clusters on Ge(001) was detected. It should be noted that a very flat wetting layer was observed for the Co/Ge(001) system, which is different for the Ni/Ge(001) system where inhomogeneous terraced domains were formed. Finally, the 2D wetting layer gradually evolves with increasing temperature into well-ordered 3D MetalxGey nanostructures, surrounded by clean, reconstructed Ge(001). Analysis of these Co and Ni germanide nanostructures shows that the growth mechanism is different: in particular the Ni/Ge system is more reactive by means of Ni bulk diffusion and results in 3D Ni germanide nanostructures which show a strong tendency to be embedded into the Ge(001) substrate. In contrast, Co germanide nanostructures are situated initially on top of the Ge(001) substrate due to the fact that Ge diffusion dominates in the low temperature range. Only at higher annealing temperatures, Co diffusion into the bulk occurs and Co germanide nanostructures penetrate into the Ge substrate. For the Co- as well as Ni-Germanide system, the nanostructures undergo Ostwald ripening phenomena in the high temperature range. The present PhD thesis thus allows to understand on the nano-scale the main growth and reaction mechanisms of the Walser and Benè rule set up about 40 years ago to describe metal/semiconductor interface reaction on the macro-scale.",,"Grzela, Tomasz",2015,,,OPUS4-3623,Dissertation
14th EEEIC International Conference on Environment and Electrical Engineering - Student Edition : Wroc&#322;aw-Ostrava-Cottbus 8th - 12th of June 2015,,"In the time of increased awareness about the environment problems by the public opinion and also intensive international efforts to reduce emissions of greenhouse gases, as well increase of the generation of electrical energy to facilitate industrial growth, the conference offers broad contribution towards achieving the goals of diversification and sustainable development. Focus of the student conference is to promote the discussion of views from scientists and students from Wroclaw University of Technology, Technical University of Ostrava and Brandenburg Technical University of Cottbus. The conference offers prominent academics and industrial practitioners from all over the world the forum for discussion about the future of electrical energy and environmental issues and presents a base for identifying directions for continuation of research.",,,2015,,,OPUS4-5678,Konferenzveröffentlichung
14th EEEIC International Conference on Environment and Electrical Engineering - Student Edition : Wroc&#322;aw-Ostrava-Cottbus 8th - 12th of June 2015,,"In the time of increased awareness about the environment problems by the public opinion and also intensive international efforts to reduce emissions of greenhouse gases, as well increase of the generation of electrical energy to facilitate industrial growth, the conference offers broad contribution towards achieving the goals of diversification and sustainable development. Focus of the student conference is to promote the discussion of views from scientists and students from Wroclaw University of Technology, Technical University of Ostrava and Brandenburg Technical University of Cottbus. The conference offers prominent academics and industrial practitioners from all over the world the forum for discussion about the future of electrical energy and environmental issues and presents a base for identifying directions for continuation of research.",,,2015,,,OPUS4-4267,Konferenzveröffentlichung
Behaviour of water drop on the insulator surface and study of electric field distribution on parallel insulators under DC,,"With the recent developments in electrical transmission system, HVDC transmission for long distances has become feasible. With this development, many insulators are being used in HVDC system. Different kinds of insulators are situated at different places (example: desert, near to sea, agriculture area, etc.) so they will get expose to different types of pollution. Pollution affects the behavior of insulation in terms of breakdown and withstand capability. The application experience of insulators under HVDC conditions is limited. There is a necessity to understand the flashover performance and to recognize key parameters in the design and dimensioning of insulators used under HVDC conditions. This dissertation presents the difference between the analysis of partial breakdowns at AC and DC. The dissertation explains the behavior of a water drop on insulator shed surface energized with DC. It deals with the moving water drop and hanging drop at the edge of the shed. There are many situations where insulator structure should be in parallel. For example, the structure of insulators in vertical disconnector equipment often is parallel. If insulators are arranged in parallel, then the behavior of the electric field is totally different. It is important to know the behavior of these insulators used in HVDC system. This report also explains the pollution and non-pollution behavior of parallel insulators energized with DC. The results can be a source of information to optimize the design and dimensioning of HVDC insulators, especially in pollution conditions.",,"Challagondla, Naresh Kumar",2015,,,OPUS4-3371,Dissertation
Vulnerability assessment of an IHP ECC implementation,,"Mathematically, cryptographic approaches are secure. This means that the time an attacker needs for finding the secret by brute forcing these approaches is about the time of the existence of our world. Practically, an algorithm implemented in hardware is a device that generates a lot of additional data during calculation. Its power consumption, electromagnetic radiation etc. can be measured, saved and analysed for the key extraction. Such attacks - the side channel analysis attacks (SCA attacks) - are significant threats when applying cryptographic algorithms. By taking the issue of physical attacks into consideration when implementing a cryptographic algorithm, it is possible to design an implementation that is resilient - at least to a certain extend - against side channel analyses. In this report, we give implementation details of the IHP accelerator for the elliptic curve point multiplication. We analysed the implemented algorithm ow and its power consumption using simulated power traces for the 130nm CMOS IHP technology. We made a horizontal power analysis attack using the difference-of-means test with the goal of finding potential SCA leakage sources, i.e. finding the operations in the algorithmic ow that are responsible for the correct extraction of the cryptographic key.",,"Bock, Estuardo Alpirez; Dyka, Zoya",2015,,,OPUS4-3490,Bericht
Slow wave resonator based tunable multi-band multi-mode injection-locked oscillators,,"In modern information technology, increasingly powerful electronic circuits are required for the targeted generation of complex signals with well-defined amplitudes and phases. In circuits of this type, oscillators frequently form the central element because of its phase noise and stability, which essentially determines the achievable precision in the signal generation. Further requirements are derived from the electronic definability of the signal properties and the operational behavior of the oscillators. Conventional oscillator circuit models autonomous circuits, mainly consist of a passive frequency-selective or phase-selective network and an active amplifier element, which together produce an oscillatory circuit via a suitable feedback. At first glance, the circuit topology seems to be quite simple, and can often be explained quite visibly. However, when it comes to describing in particular the very important phase noise dynamics and stability of oscillators, it very soon becomes apparent that highly complex structures are involved. A fundamental difficulty in the theoretical description arises due to the non-linear behavior of oscillators, the understanding of which is crucial for a reliable description of jitter and oscillator phase noise. The resonant condition of oscillators arises due to the fact that the noise in the oscillator circuit is always present in the system, which is amplified in a frequency-selective manner to the extent that a stable oscillation arises at most at a fixed frequency because of non-linear limitation of the amplification. The frequency selectivity arises due to the frequency selectivity or phase selectivity of the passive feedback path. The non-linear limitation of the amplification in the oscillator normally results in a very reliable control of the amplitude noise of the output oscillation. It is well understood that any particular oscillator's phase noise could be improved by increasing the generated signal amplitude or increasing the quality factor of the resonant network. Increasing the signal level is limited by the utilized supply voltage or the break down limits of transistors and cannot be increased further to improve the phase noise. Accordingly, the remaining phase noise, which can normally be minimized via resonating circuits with pronounced phase selectivity and therefore a high quality factor resonator, is of great importance for oscillators. Traditional high Q-factor resonators (ceramic resonator, surface acoustic wave, bulk acoustic wave, dielectric resonator, YIG resonator, Whispering gallery mode resonator, Optoelectronic resonator, etc.) are usually 3-dimensional structures and bulky for both handheld and test-measurement equipments and does not offer integration using current foundry technology. The current and later generation wireless communication market is pushing the need for miniaturization to its limits. Printed coupled transmission line resonator is a promising alternative due to its ease of integration and compatibility with planar fabrication processes but limited by its large physical size and low quality factor, making it a challenging choice to design low phase-noise oscillators. This problem is more prominent in integrated circuits (ICs) where high degrees of thin conductor losses reduce the quality factor by orders of magnitude compared to hybrid circuit technologies. This thesis describes the design and investigation of a variation of printed resonators using Möbius slow-wave and Metamaterial structures for the applications in oscillator circuits. A novel Möbius slow-wave mode-coupled structure offers additional degrees of freedom (higher Q-factor and multi-band characteristics for a given physical size) as compared to conventional transmission line printed resonators. A design study has been carried out to optimize the phase noise performance by using the novel resonant structures (mode-coupled, slow-wave, Möbius strips, evanescent mode, negative index material-Metamaterial) in conjunction with mode locking and injection locking for improving the overall performances, beyond the limits imposed by conventional limitations. The thesis also covers a broad spectrum of research on DRO and OEO ranging from practical aspects of circuit implementation and measurement, including the modeling of optical fiber delay line used as a thermally stable high Q-factor resonator structure. This thesis is research work carried out from 2004-2014, organized in 11 chapters, theoretical and experimental results documented by a range of specific measurement results and substantiated by over 200 scientific publications over dozen patents. The Metamaterial Möbius technology discussed in this thesis can open new era in the field of imaging, sensors, cloaking, energy harvesting and energy efficient microwave circuit and system Solutions.",,"Poddar, Ajay",2014,,,OPUS4-3193,Habilitation
Search for additional Higgs bosons with multi b-quark final states at LHC,,"The Higgs mechanism is responsible for the spontaneous breaking of the electroweak symmetry leading to the generation of masses of fermions and weak bosons. This thesis is devoted to search for the neutral supersymmetric Higgs particles &#934;=h, H and A decaying into b quarks produced in association with at least one more b quark at the Large Hadron Collider. Here the study of the final states characterized by three b-tagged jets is described in detail. The analysis was performed using data corresponding to 2.7 &#8722; 4.8 fb^&#8722;1 integrated luminosity of pp collisions with a centre-of-mass energy of 7 TeV collected in 2011 with the CMS detector. Two analysis scenarios were adopted to perform a search for neutral Higgs bosons of low and medium masses, 90 GeV &#8804; M&#934; < 180 GeV and 180 &#8804; GeV M&#934; &#8804; 350 GeV, respectively. Two-dimensional templates, built up from double-b-tagged data and based on the invariant mass of the two leading b jets and a variable reflecting b-jet properties of three leading jets, are used to model the background. The signal is modeled by templates obtained from Monte Carlo simulation. Various systematic effects affecting the signal efficiency and changing shapes of the signal and background templates were investigated. The fitting machinery, based on a binned least-squares fit of the signal and background templates and the systematics model dependent on the hypothesized mass of the pseudoscalar Higgs particle A, was developed to extract the signal and background yields from the data. No significant evidence for the production of the Higgs bosons is found. Using the CLS method, we set cross section times branching fraction upper limits at 95% confidence level (CL) on the production of such neutral Higgs bosons &#934; in the mass range from 90 GeV to 350 GeV. The observed exclusion limits are well within the expected ±2&#963; band. The benchmark scenario of the Minimal Supersymmetric Standard Model, denoted as mmax , with the two choices of the Higgsino mass parameter, &#956; = +200 GeV and &#956; = &#8722;200 GeV is considered. The obtained 95% CL upper limits on &#963; (pp &#8594; bb + &#934;) × BR(&#934; &#8594; bb) are interpreted as the upper limits on the MSSM parameter tan &#946; . Ranges 27 &#8804; tan &#946; &#8804; 51 and 22 &#8804; tan &#946; &#8804; 37 for the masses of the Higgs boson from 90 to 350 GeV are ruled out at &#956; = +200 GeV and &#956; = &#8722;200 GeV, respectively. The 95% CL limits on tan &#946; obtained in this channel supersede previous tan &#946; limits established by CDF and D0 experiments.",,"Marfin, Ihar",2014,,,OPUS4-3281,Dissertation
Development of Beam Halo Monitors for the European XFEL using radiation hard sensors and demonstration of the technology at FLASH,,"The European X-Ray Free-Electron Laser (E-XFEL), currently under construction in Hamburg, Germany, is intended to be an international linear accelerator (linac) based user facility. Its electron beam can carry maximal average power of 600 kW. A beam with such a high power needs to be carefully transmitted through the machine and safely dumped after utilization. This is supported by various diagnostics tools. A Beam Halo Monitor (BHM) based on synthetic diamond and sapphire sensors has been designed. Diamond sensors are developed by the company element6 for the detection of ionizing radiation and used previously elsewhere. Sapphire sensors are in this thesis applied for the first time. The BHM concept has been applied already at the Free-electron Laser in Hamburg (FLASH). A module with four diamond and four sapphire sensors was designed, installed inside the beam pipe, commissioned, calibrated and has been successfully operated for 4 years. The system contributed significantly to safe and efficient operation of FLASH. Both types of the sensors for the BHM were characterized. Measurements of radiation tolerance are done in a 10 MeV electron beam for polycrystalline CVD (pCVD) diamond sensors for the first time up to a dose of 10 MGy and for sapphire sensors up to 5 MGy. The charge collection efficiency (CCE) drops as a function of the absorbed dose, is however still sufficient for application as a BHM. To improve a main sensor characteristic, the charge collection efficiency, for sapphire sensors the impurity concentration was reduced and different growth techniques were compared. Finally, charge collection efficiency of about 5 % for a bias voltage of 500 V was reached. The BHM concept for the XFEL is designed and in the construction phase.",,"Ignatenko, Alexandr",2014,,,OPUS4-3475,Dissertation
Animal biodiversity and food web restoration based on large vertebrate carcasses,,"Carcasses of large vertebrate animals are integral elements in the natural environment. The aim of the present study is to clarify the relation between large carcasses and local ecosystems. It has been investigated which and how many animals are directly or indirectly involved into the carcass decomposition process, and whether there is a succession of community pattern during different carcass decomposition stages. A special focus was on the question how the temporal and the spatial distribution of arthropods are influenced by the carcass and its properties. A new classification of decomposition stages is proposed based on a new openness index for a carcass. Three carcass food web models for the research area were composed dependent on different seasons in the course of the year: Carcass exposed in spring, summer, and winter, respectively. Subsequently, the feasibility of using carcasses as a tool for food web restoration on a regional scale has been discussed. From 2009 to 2011, in total, nine different carcasses from Meles meles, Capreolus capreolus, Cervus elaphus, and Sus scrofa were exposed in the research area, a former military training area situated in Eastern Germany. Pitfall traps were used to collect arthropods visiting the carcasses. Bird's and Mammal's attendance have been detected by automatic cameras and direct observation. In total, more than 112,000 arthropods from 25 taxa were identified. For Coleoptera Silphidae, Geotrupidae, Trogidae, Staphylinidae (partly) and Heteroptera the investigation could be carried out on species level. The existence of carcasses in the research area significantly increased arthropod diversity and abundance. Long term exposed carcasses significantly influenced vertebrates occurrence, vegetation and the surrounding soil as to diversity and various environmental conditions, respectively. The main consumers of carcasses in summer were various arthropods, Corvus corax and Haliaeetus albicilla. Besides the already well-known carrion arthropods, Orthoptera, Lepidoptera, and Apocrita were observed using carcasses directly. In winter, the main consumers of carcasses were Sus scrofa, Vulpes vulpes, Canis lupus, Corvus corax, and Haliaeetus albicilla. By multivariate analysis it could be shown that the main factors influencing the occurrences of arthropods are the weight and the degree of openness of the carcass, and the main factor for the carcasses decomposition process is the openness index of the carcass. Carcass exposition is a cheap and efficient method to use large wild games which did not die from disease for the food web restoration in the research area.",,"Gu, Xiaoying",2014,,,OPUS4-3075,Dissertation
Adaptive Polynomial Tabulation : a computationally efficient strategy for complex kinetics,,"In this work Adaptive Polynomial Tabulation (APT) is presented. It is a new approach to solve the initial value chemical rate equation system. In this approach zeroeth, first and second order polynomials are used in real-time to approximate the solution of the initial value chemical rate equation system. The sizes of the local regions encountered for the different orders of polynomial approximation are calculated in real-time. To improve accuracy the chemical state space is partitioned into hypercubes. During calculations the hypercubes accessed by the reactive mixture are divided into adaptive hypercubes depending on the accuracy of the local solution. Mixture initial conditions are stored in the adaptive hypercubes. Around each stored initial condition two concentric ellipsoids of accuracy (EOA) are defined. These include the ISAT and identical EOAs. The time evolution of mixture initial conditions which encounter an identical and ISAT EOA are approximated by zero and first order polynomials respectively. With a certain number of stored initial conditions within an adaptive hypercube, its second order polynomial coefficients are constructed from the stored initial conditions. The time evolution of additional mixture initial conditions that encounter this adaptive hypercube are approximated with second order polynomials. The APT model is simplified by the replacement of the entire set of species mass fractions with a progress variable based on the enthalpy of formation evaluated at 298 K. APT has 3 degrees of freedom which include the progress variable, total enthalpy and pressure. The APT model was tested with a zero dimensional Stochastic Reactor Model (SRM) for HCCI engine combustion. A skeletal n-heptane/toluene mechanism with 148 chemical species and 1281 reactions was used. In the tests, the HCCI engine simulations using APT were in very good agreement with the model calculations using the ODE solver. The cool flame and main ignition events were accurately captured. The major and minor species were also accurately captured by APT. In SRM-HCCI calculations without cyclic variations, a computational speed up factor greater than 1000 was obtained when APT was used for all the operating points considered without significant loss in accuracy. For the SRM-HCCI engine calculations with cyclic variations, APT demonstrated a computational speed up exceeding 12 without significant loss in accuracy.",,"Ebenezer, Ngozi",2014,,,OPUS4-3005,Dissertation
A framework to analyse community energy in towns and villages,,"The article develops an analytical framework to explain the successes and failures of local community energy projects in the countryside. Theoretical elements based on ownership, technology acceptance, value chains and public opinions are developed and synthesised in two concepts: ´technical complexity and its antagonist social complexity. The achievement of a mature community energy regime is explained as a continuous process of consecutive single steps in both social and technical arenas.",,"Kunze, Conrad",2014,,,OPUS4-2982,Bericht
Enabling local climate change response - a conceptual approach for the governance and management of Community-Based Adaptation (CBA) with a special focus on Vietnam,,"Community-Based Adaptation (CBA) to climate change is a people-centred approach designed for the enablement of communities to collectively develop strategies to respond to local impacts that directly affect their lives and livelihoods. Nevertheless, CBA requires political support and the integration into larger-scale adaptation plans and policies; as the scope of local initiatives is rather small, they cannot substitute national or city-level adaptation efforts, but they may be a supplement as short- or medium-term response measures. Despite the success of single CBA pilot projects, the institutionalisation of CBA and its integration as a bottom-up approach into larger-scale adaptation plans and policies is definitely a challenge: firstly, the potential of CBA is still overlooked by decision-makers and planners; secondly, the decentralisation of decision-making is still underdeveloped in many countries and communities are not yet empowered and enabled to actively participate; and thirdly, there is lack of approaches to 'scale-out' and 'scale-up' successful CBA pilot projects. Consequently, this doctoral thesis aims at going beyond the work of theorists and focuses on the identification of ways to institutionalise CBA. In the theoretical section of this thesis, an academic concept of CBA is formulated; the scope of CBA is defined and challenges for taking CBA beyond the pilot stage are identified. In a further step, a governance and management concept for the integration of CBA as a bottom-up approach into top-down planning approaches is developed. In order to do that, suitable existing governance and management concepts are identified and transferable concept components are combined. The first result of this concept development step is an ideal-typical 'CBA Governance Management Model' (CBA-GMM), which combines concepts for a policy instrument and a pro-poor funding mechanism, for a governance approach, based on multi-level and network governance, as well as for a management approach that altogether may theoretically help to enable CBA activities. In a next step, the CBA-GMM is applied to the real case of Vietnam. After the assessment of the political and institutional framework, its strengths, constraints and challenges with regard to the institutionalisation of CBA, an 'Applied CBA Governance Management Model' for Vietnam (CBA-AGMM) is developed, which proposes a concept for the integration of CBA into the strongly hierarchical structure of the Vietnamese administrative and decision-making structure. This doctoral thesis shows that it is theoretically possible to integrate CBA as a bottom-up approach into larger-scale adaptation efforts, while it honestly reflects the constraints for putting it into practice.",,"Schinkel, Ulrike",2014,,,OPUS4-3524,Dissertation
The potential of strategic environmental assessment for integrated and sustainable water resources management in the Republic of Yemen : Scenario-based strategic assessment of the water resources policies adopted in 'Yemen's Strategic Vision 2025',,"Yemen is one of the most water-stressed countries in the world. The water deficit has been aggravated by the rapidly increasing demands for both surface and groundwater resources that are being unsustainably exploited. To address the country's severe water scarcity, the government has adopted long-term intervention policies as stated in 'Yemen's Strategic Vision 2025'. These policies are aimed at restoring the balance between water demand and availability, and at reducing the existing water deficit. Although 11 years have passed since this vision was adopted, the water deficit is still on the rise. The present situation raises questions about the efficiency of the intervention policies adopted by 'Yemen's Strategic Vision 2025' and about the effectiveness of implementing these policies. Another fundamental question pertains to the availability of a strategic assessment tool in the water resources sector that can be used to assess strategically future and current policies, strategies and plans, in order to ensure their efficiency in supporting water resources and in producing the positive impacts for which these strategic initiatives were developed in the first place. Strategic Environmental Assessment (SEA) is an assessment tool designed to function at a strategic level and help to bring aspects of environmental sustainability into the decisionmaking process. This research aims to demonstrate the potential of SEA in enhancing environmental sustainability in water policies for achieving sustainability of water resources in Yemen. In order to show the potential of SEA in the Yemeni water resources sector, this research has applied SEA methodologies and adopted a scenario-building approach for assessing the intervention policies adopted by 'Yemen's Strategic Vision 2025' to support augmentation of water resources. Qualitative and quantitative approaches have been used in this research. Quantitative historical data on water availability, water demand and water savings by interventions have been collected from the databases of national institutions and international organizations concerned. Statistical analyses have been used to project future trends until 2025. Qualitative analyses of relevant studies and reports covering the environmental, administrative, sociocultural and political-economic aspects of water resources management in Yemen have been implemented as well. In addition, 13 semi-structured key informant interviews have been conducted with decision-makers, managers and leading experts in the water and irrigation sectors. The research produced three future scenarios for the total water balance that may play out until 2025 in Yemen. These scenarios provide impact assessment and alternatives' comparison of the existing intervention policies. The resulting scenarios are as follows: the 'Business as Usual' scenario, which forms an assessment of currently applied interventions and provides an image for the future, if current interventions are maintained at the same pace; the 'Do-nothing' scenario representing the situation if no interventions are implemented; and the 'Sustainability' scenario, which represents the potential future of the total water balance if existing interventions are to be scaled up and out. The findings confirm the significant potential of currently adopted intervention policies to support water resources. They also reveal that the current level of implementing the intervention policies has hindered the potential of these intervention policies in achieving the expected positive impact on the water balance by 2025. In order to achieve a significant decrease in the water deficit, the strategic quantitative targets that need to be implemented were identified. The methodology followed in implementing the research and achieving the findings demonstrates the potential of SEA in enhancing environmental sustainability in water policies for achieving integrated and sustainable water resources management in Yemen. The recommendations of the research covered improving the existing water balance as well as improving the assessment and planning context in the water resources sector. In order to improve the water balance situation, the research recommends implementing quantitative targets for water savings and augmentations, such as those developed by this research. These targets have been identified based on the capacities of sectors implementing these interventions. The research also recommends further decentralization of planning and management of water resources and the establishment of Water User Associations (WUAs) as the main vehicles for ensuring sustainable planning and management of water resources, including the scale out of interventions, subject to assessment in this research. In order to improve assessment and planning of water resources, the research recommends the adoption of SEA, the updating of water resources data and conducting regular assessments of policies, plans and programmes as part of monitoring their impact and providing a chance for amending these policies and strategies, if required, to achieve sustainability of water resources.",,"Al-Ghorbany, Amer",2014,,,OPUS4-2963,Dissertation
Measuring urban morphology for adaptation to climate change in Ho Chi Minh City,,"Urban morphology is used in many developed countries to classify and manage the dis-tribution of urban functions. In urban planning, it helps to identify the emerging prob-lems and solve the disorder of urban functions. The megacity Ho Chi Minh City has faced many problems with uncontrollable urbanization, urban management and plan-ning. It has received increasing tropical storms and cyclones which caused more heavy rains in recent decades. Rapid urbanization has caused the increase of built-up coverage with disordered typologies, incomplete infrastructure and urban-peripheral instability. In the flooding context, these problems have increased more seriously with flooding impacts and caused uncontrollable planning and management in the city. This study applies the urban morphology method to measure flood impacts on urban functions and develop the adaptive solutions for flooding adaptation for Ho Chi Minh City. The methods in this study are based on applying fractal geometry, GIS and Remote Sensing on large-scale maps for measuring the urban morphology. The land-use map and the building footprints map of 2010 were founded to analyze the distribution of urban areas by high resolution of satellite images and large scale GIS data. The fractal geometry was a setting based on Avenue program of Arcview GIS to measure the urban morphology. This formed a key input for the multi-criteria analysis (MCA) method that investigated the cause of flood impacts and suggested the solution for flooding adapta-tion. In addition, alterations of lakes, ponds and watercourse from 1995 to 2009 were explored. The study showed HCMC had problems on irrational development in residential densi-ties areas and urban functions, and the uneven development of population and residen-tial density between the urban areas: too much in the urban districts (about 300 to 500 persons per hectare per block and coverage ratio 0.7 - 0.9). This pushed the increasing demand on built-up area and filled-up rivers and canals (About 80 percent of original ponds and lakes in inner-center were filled-up in the past; and 63 percent of ponds and lakes have been filled-up in Sub-Districts and new-urban-development areas). It made the imbalance between the permeability of land surface and the run-off water flows; then leads the inundation to increase. This is the main reason for reducing the water-storage capacity in rainy season. Flooding in urban residential area was more im-pacted than in rural residential area, higher level and longer flood time; while flooding in the rainy season due to high tides, heavy rains or both was the emerging and uncon-trollable problems. For flooding adaptation, urban morphology analysis helped to figure out the potential areas in the city could be used for reducing flooding impacts in urban areas. There are many low-density residential areas in above 1.5 meter AMSL areas in the North, Northwest and Northeast areas of the city which could be developed with complete infrastructure and urban services to attract people from high-density residential areas impacted deeply by floods in the center. These potential areas could be the long-term strategic solution to flooding adaptation for HCMC. The results also suggested that some current flooded areas would be re-planned or returned to be the water-storage and permeable areas (such as green parks, ponds and lakes). This re-planning would improve the city landscape and increase the permeable surface, green spaces and open spaces to HCMC. More green spaces, lakes and ponds will also help to reduce the temperature of urban center in the dry season. This adaptation solution would reduce at least 25 percent of current flooded areas in urban center. The protection and constructed restriction of current agricultural areas in peri-urban Districts would maintain the infil-tration and green-tree areas. Furthermore, the complete drainage system would help to reduce better flood for these areas. Finally, fully dredging river and canal system of the city would reduce about 25 to 30 percent of current flooded areas.",,"Le, Thanh Hoa",2014,,,OPUS4-2860,Dissertation
The Socioeconomic impact assessment of climate change in Ho Chi Minh City,,"Historically as a city situated in a low-lying area a Ho Chi Minh City has been exposed to floods. Ho Chi Minh City is a megacity with uncontrollable urbanization and dynam-ic economies. In recent years, flood has become a serious problem with a multitude of follow-on impacts. It received more heavy rains affected by tropical storms and cy-clones. Further urbanization and future changes in climate are likely to increase flood risks. People have faced the flood impacts on the socioeconomic aspects in recent dec-ades. This study researched on 450 households in different spaces of the inner center (old districts), developed center (urban districts) and new-developing areas (peri-districts) and in different geographical elevations to identify the impacts of flooding in various space and time; and various problems on households' socioeconomic aspects in flood residential areas. The multi-criteria analyses in GIS and with of the combination SPSS analysis, the sur-veyed households were identified by their location on the topographic map to clarify the flooding reasons and the types of flood in the areas. The 450 households were chosen in flood residential areas and selected in three categories of characteristics: (1) 150 poor households in flood housing areas; (2) 150 poor households in non-flood housing areas; and (3) 150 higher-income households in non-flood housing areas. This disparity was to analyze the different flood impacts on socioeconomic aspects and on household capitals amongst them. The linear regression in SPSS analysis was used to clarify the relation-ships between flood types with space factor (geographical elevation) and time factors (flood months in year, and flood years in residential areas). This test gave the supports to the reliability of the study results. By geographical elevation analysis, flood impacted on the areas in three main types: (1) flood by rain; (2) flood by tide; and (3) flood by both rain and tide. The tidal flood oc-cupied the low-elevation areas; flood by rain invaded the widespread higher-elevation areas; and the mix type of flood occupied the transition areas between flood areas by rain and by tide. Lower land had the deeper flood level, however; many of high-land areas were flooded in this city. Flood in residential areas had caused flood problems on streets, sidewalks (housing pavements), residential drainage system, water supply and electric power. In the poor households of Group One, flood in residential areas impacted their housing areas. To protect housing from flooding, many households had to invest their income for house rising or rebuilding or pavement rising, etc. They also privately invested for repairing or new buying their housing facilities, furniture and other appli-ances. Their income was lost and deficit. To the household capitals analysis, households were impacted more on physical, financial, natural and human capitals. The poor households in Group One had the most vulnerabilities amongst three groups, whilst there was no support from social organizations and government at levels. The household strategies developed in this study are to support people in flood and flood-prone areas conserving their capabilities to achieve the strategic outcome for sustainable develop-ment.",,"Nguyen, Thi Phuong Chau",2014,,,OPUS4-2859,Dissertation
Improvement of flood risk assessment under climate change in Ho Chi Minh City with GIS applications,,"Ho Chi Minh City is the largest city in VN. The city is the most important center of economy, society and culture in the southern region of Vietnam. However, due to characteristics of natural conditions with low topography and borders touch the sea so that since the late 20th century with the rapid economic and urban development there are environmental problems have arisen. One of the problems is flooding issue caused by high tide. With these natural conditions and sea level rise of climate change in the future, Ho Chi Minh City is considered as one of the most affected and damaged cities in the world. Therefore, many policies have been set out from the national to local levels in Vietnam to prepare for adaptability of impacts and risks of the sea level rise and the climate change. And this has also been considered in Ho Chi Minh City as the development policies of the city authorities have to consider in the context of the sea level rise and the climate change. A number of researches have been conducted to assess the impact of climate change to Ho Chi Minh City in the future. However, these researches are still need to be enhanced further. The flooding problem is a major issue of the sea level rise in Ho Chi Minh City. And to make a good result, the flood model needs a lot of requirements that ensure fine quality of input data, suitable model and a relied procedure. In the available research, the input data is not really the highest quality in the available context in Ho Chi Minh City. As the flood model is implemented, one of the input data requirements of the model is information detail of elevation in the flooded area. And this is more necessary than in geophysical urban areas such as Ho Chi Minh City. And to assess fully flood risk issues for flooding caused by tidal phenomenon in Ho Chi Minh City, the determination of many characteristics of flood model is very useful for users who need to apply the results of the model for the planning development in Ho Chi Minh City in the future. Besides adopting a uniform environment as GIS for managing all the data of flooding problem and making conditions for the development of decision support systems is very necessary for flood management in the future. The research has been carried out and its results have been generated on the flood risk assessment associated context of the sea level rise due to climate change with high emissions scenario A1FI in 2030 for the current houses, the population and the land use types. The results have shown a lot of the areas where are inundated in the future with the increasing flooding duration, depth and frequency even though they are not flooded at the current because there are some protective structures. This will be helpful for suggesting a forecast of the development direction to decision makers in Ho Chi Minh City for next time period. And the last part is the proposal for decision and policy makers, authorities and planners as well. Moreover, the results of this research can be used as the references and the foundations for further researches and so that the problems that Ho Chi Minh City may be encountered due to flood risk caused by climate change to the economic and social aspects of the development in Ho Chi Minh City will encounter. And the problem of adaptation to climate change will be more completed and more thoroughly so that it is to minimize the damage of climate change for the city.",,"Tran, Thong Nhat",2014,,,OPUS4-3078,Dissertation
On-Wafer calibration techniques enabling accurate characterization of high-performance silicon devices at the mm-wave range and beyond,,"This work addressed the challenges of accurate mm-wave characterization of devices fabricated in advanced semiconductor technologies. It developed the in-situ calibration solution that is easy to be implemented for silicon technologies. The new technique was verified up to 110 GHz on three difference processes: high performance SiGe:C BiCMOS from IHP Microelectronics (Germany), BiCMOS9MMW from STMicroelectronics (France), and RF CMOS 8SF from IBM Microelectronics (USA). The measurement frequency was solely limited by the capability of the test equipment. Practical results demonstrated that proposed in-situ calibration significantly outperforms the convention method independently on the process specifics and complexity. Some important aspects of the on-wafer S-parameter measurement assurance were presented as well. The discussion included the analysis of the calibration residual errors caused by the improper boundary conditions of coplanar calibration standards and the impact of the RF probe tip design. In conclusion, some suggestions for further accuracy improvement of the proposed method are given.",,"Rumiantsev, Andrej",2014,,,OPUS4-2962,Dissertation
Large Eddy Simulations Modelling of flameless combustion,,"The environmental emergency has led to the development of new combustion technologies. In this context, flameless combustion (FC in this manuscript) offers the prospect of a less polluting and more efficient technology. In FC, combustion is strongly diluted with recirculated burnt gases. Consequently the oxygen content is reduced and temperature peaks are smoothed, yielding reduced heat release. These conditions dramatically reduce the conditions of NO pollutant formation and increase the efficiency of the combustion process. Being FC a relatively new technology, it still needs optimization and R&D, which can be expensive and time consuming. Potentially, CFD can reduce both the financial costs as well as the R&D projects length. The context in which this thesis is inserted is exactly the numerical modeling of FC, by using Large Eddy Smulations for its better prediction of the turbulent ternary mixing (fuel - burnt gases -air), compared to RANS. This work has been divided into two main parts. In the first, combustion in FC has been investigated by means of a new tabulated combustion model initially written in the context of the EC-KIAI project and developed and adapted to FC in this thesis. The model uses diluted homogeneous reactors DHR to simulate FC and it was developed to account for under adiabatic enthalpy losses and the ternary mixing typical of FC. The model was firstly validated on a non-premixed flame academical configuration called Flame D and subsequently on a real FC combustor from the work of Verissimo et al. The results obtained for these configurations are quite correct although some discrepancies in CO prediction are observed. In the second part of the thesis, the NO pollutant modeling in FC is investigated. With this aim, the Diffusion Flame - NO relaxation approach DF-NORA was developed. It consists in tabulating the NO relaxation towards equilibrium of the NO source term in a flamelet structure. As done in the first part, the model was first validated on Flame D and then employed in a real FC configuration. Results are quite satisfactory in both config- urations. The encouraging results obtained in this work open the possibility of applying the proposed developments to real industrial configurations in the future.",,"Locci, Carlo",2014,,,OPUS4-3288,Dissertation
Metal Injection Moulding of Titanium-Niobium alloys for biomedical applications,,"The main subject of this work was the investigation of sintering behavior, microstructure, mechanical properties and biocompatibility of metal injection moulded (MIM) Ti-Nb alloys for biomedical applications. Commercially pure titanium (CP-Ti) samples were also fabricated by MIM as a reference. The sintering behavior of MIM Ti-Nb alloys was studied at first, in order to roughly determine the sintering parameters in the following investigations. Dilatometry was applied to investigate the linear shrinkage of MIM Ti-Nb samples from room temperature to 1500 °C at a heating rate of 3 °C/min under argon atmosphere. Various sintering parameters and Nb contents were used to investigate their influences on microstructure and mechanical properties of MIM Ti-Nb alloys by means of density measurements, optical microscopy (OM), X-ray diffraction (XRD), scanning electron microscopy (SEM) and mechanical testing. Transmission electron microscopy (TEM) and high energy X-ray diffraction (HEXRD) measurement were applied to investigate the nature and precipitation of the unexpected titanium carbide precipitates in MIM Ti-Nb alloys. Initial cell adhesion and cell proliferation assays of human umbilical cord perivascular cells (HUCPV) on MIM Ti-Nb alloys were performed for biocompatibility characterization. The results of this work show that MIM Ti-Nb and MIM CP-Ti samples have been successfully fabricated and the as-sintered samples show good shape retention without distortion compared to the green sample. The sintering process of MIM Ti-Nb alloys consists of three main steps - Ti-diffusion step, Ti-Nb-diffusion step and Matrix-diffusion step. With increasing sintering temperatures and time, MIM Ti-Nb alloys exhibit lower porosity and higher Young's modulus. A higher Nb content in MIM Ti-Nb alloys leads to an increase of carbide area fraction and porosity. The three factors - Nb content, carbide area fraction and porosity - determine the mechanical properties of MIM Ti-Nb alloys. An increase of Nb content and amount of carbides as well as a lowered porosity lead to a higher tensile strength. A decrease of Young's modulus can be expected with higher Nb content and porosity. A high amount of titanium carbides can result in very poor ductility, but annealing and quenching process can significantly improve the elongation by dissolving the carbides. MIM Ti-Nb alloys exhibit good biocompatibility, indicating their potential for implant applications.",,"Zhao, Dapeng",2014,,,OPUS4-2961,Dissertation
Conflictive delisting process of a World Heritage Site in Germany: the case of the Dresden Elbe Valley,,"This research comprises an analysis concerning the conflict between the State Party Germany to the World Heritage Convention and UNESCO in the case of the Dresden Elbe Valley. Through a historical and legal analysis, this research aims to ascertain the reasons for this conflict, as well as the impossibility of finding a compromise. First, the conflict in the core of the Dresden Elbe Valley World Heritage Site caused by the construction of the Waldschlößchenbrücke, which is the object of study in this research, is anchored in its context of the City of Dresden. Thus, the object of the conflict, the Waldschlößchenbrücke, is presented in its historical and geo-spatial context in order to shed light on the elements that triggered the conflict. Secondly, the conflict is anchored within the German legal context through the analysis of the legal procedures concerning the binding effects of the World Heritage Convention for the Federal Republic of Germany and the environmental concerns rendered by the construction of the Waldschlößchenbrücke. Based on legal commentaries of the courts' decisions, a discussion on the non-transposition of the World Heritage concepts in the Federal Republic of Germany is implemented. Thirdly, the State Party Germany to the World Heritage Convention and UNESCO are confronted. A review of the concept of cultural landscape in the context of the World Heritage Convention, adapted to the case of the Dresden Elbe Valley, is first implemented. Subsequently, a commentary on the legally binding effects for the States Parties to the World Heritage Convention is elaborated upon, as well as a deconstruction of the step-by-step decisions from the inscription to the delisting of the Dresden Elbe Valley from the World Heritage List. Fourthly, an evaluation is developed concerning the concept of Historic Urban Landscape as an action plan capable of solving the conflict between urban development and heritage protection, and adapted to the German context. Finally, as a conclusion to this research, recommendations are drawn based on the conflict opposing UNESCO and the State Party Germany to the World Heritage Convention towards the Dresden Elbe Valley. These recommendations are addressed to the City of Dresden, the Free State of Saxony, the Federal Republic of Germany and UNESCO.",,"Gaillard, Bénédicte",2014,,,OPUS4-3031,Dissertation
Lab-based in-situ X-ray microscopy - methodical developments and applications in materials science and microelectronics,,"The method of microscopic imaging using X-rays and diffractive lenses was developed at synchrotron radiation facilities and it was recently transferred to systems with laboratory X-ray sources. The first part of this thesis focuses on instrumentation, in particular on the fabrication, characterization, and application of multilayer Laue lenses (MLL). The second part describes a micromechanical in-situ test that is used to study crack propagation with X-ray microscopy in microchips in a dedicated fracture mechanics experiment called micro double cantilever beam test (MicroDCB). MLLs were fabricated from WSi2/Si multilayer coatings using mechanical preparation and focused ion beam milling. Initial characterization of the obtained lenses using scanning electron microscopy and X-ray microscopy was used to evaluate the quality of the multilayer stack and particularly to identify geometrical imperfections of individual lens elements. Crossed partial MLLs were assembled as a compact lens device for two-dimensional operation, i.e. point focusing of synchrotron radiation or full-field transmission imaging. The optical properties were simulated using a geometrical optics approximation and a physical optics model. Experimental results verify full-field imaging using crossed partial MLLs with a focal length of 8.0 mm for Cu-Ka radiation in a laboratory X-ray microscope. Sub-100 nm resolution is shown and remaining aberrations are discussed. So-called wedged MLLs employ dynamic diffraction to increase the diffraction efficiency. A fabrication process is presented that allows a subsequent geometrical modification of the lens element using a stress layer. Thus, the wedged geometry is realized independently of the multilayer coating. The resulting layer tilt is measured using a laboratory X-ray microscope. First investigations of such wedged MLLs with synchrotron radiation at a photon energy E=15.25 keV show an enhancement of the diffraction efficiency of 57 % in comparison to a tilted MLL with the same dimensions. The long working distance of the X-ray microscope facilitates the integration of customized equipment to perform in-situ experiments. The MicroDCB tester was designed and built to drive a crack in an appropriately prepared specimen. It is compatible with the X-ray microscope and it allows tomographic studies under load. In particular, the method was applied to investigate crack propagation in the on-chip interconnect stack of advanced microelectronics products. Stable crack propagation at this location was achieved. Subsequent tomographies were acquired at several load steps. The reconstructed datasets show no critical distortions. This test is assumed to provide valuable information about crack propagation such heterogeneous structures, what is of interest to address reliability issues.",,"Niese, Sven",2014,,,OPUS4-3566,Dissertation
Comparison of stochastic simulation tools,,This report compares some stochastic simulation tools for biochemical reaction networks. The stochastic simulation tools are selected on the basis of some selection criteria. Simulations are performed for the different stochastic simulation tools on different benchmark models. This report gives an overview of how the comparison is carried out for the chosen tools. The tools are compared on a common evaluation protocol. The evaluation protocol comprises a set of benchmark models along with the parameters which are provided as input to the tools. The benchmark models are represented as Petri nets and fed in SBML (System Biology Markup Language) to the different tools. Experiments are performed on each tool and the results are recorded. The tools are finally compared based on the comparison criteria.,,"Sinha, Aman",2014,,,OPUS4-3146,Bericht
About the conservation of cultural landscapes: sustainability or unviability? A comparative study on the emergent landscape management in heritage sites in mountain regions: the Andes and the Pyrenees,,"Cultural landscapes have become categories of increasing use in the nominations to the World Heritage, because they provide frameworks for the integration of alternative understandings of heritage into the List. Nevertheless, the concept of cultural landscape takes its roots within a Western naturalist ontology. By assuming this ontology the interpretation of heritage sites is based on the division between nature and culture. The lack of a model of protection designed for the integration of all categories of heritage is evident, with the models used following the culture/nature and tangible/intangible divides. In order to study this problem, a comparative approach has been used. Two sites from mountain areas have been selected as case studies. The Ordesa and Monte Perdido National Park in Spain has been part of the transnational mixed cultural and natural heritage property in the World Heritage List Pyrenees/Mont Perdu since 1997, shared with France. The Archaeological Park of Ollantaytambo, neighbor to the Sanctuary of Machu Picchu in Peru, is included in the serial and transnational property Qhapaq Ñan/Andean Road System inscribed in the List in 2014. These sites are protected under two different models: the first focused on the conservation of nature and the second on the conservation of the past. Nevertheless, both sites have been nominated as cultural landscapes based on the presence of Intangible Cultural Heritage maintained by agropastoral communities inhabiting them. The focus is to put in question the relevance of the concepts of conservation and sustainability in these contexts and to propose landscape management as an alternative that implies maintenance and at the same time adaptation to change. The methodological design is based on a qualitative approach. The focus is the analysis of the 'emergent landscape management', defined as a self-organized process resulting from the interactions between the most influential actors in landscapes - the state, local communities and visitors -, ultimately leading to synergies between these actors' practices. The results show that, first, the diversity of approaches to the notion of ""landscape"" entails the lack of precision of the object to be conserved. The definition set in the Operational Guidelines of the 1972 World Heritage Convention presents the concept from different epistemological perspectives. Contrasted with the criteria under which these sites have been justified as World Heritage Cultural Landscapes, an inherent contradiction is evident between the models of protection and the continuity of the way of life of local communities that represent their heritage value. Second, three landscapes have been identified based upon the model of the emergent landscape management: the landscape as a container; the landscape as habitat; and the landscape as picture. Three sets of maps, corresponding with each group of actors portray the results. Nevertheless, the groups and its understandings are not close. Key actors have been found playing roles in different groups. An overlay of the maps shows the potential for common ground connected by the key actors. Finally, even if these sites represent particular cases, they exemplify the need to reflect upon the inherent contradictions of the current conservation system. In order to develop comprehensive strategies for the viability of cultural landscapes alternatives for the continuity and autonomy of local communities need to be reflected upon.",,"Ishizawa, Maya",2014,,,OPUS4-3064,Dissertation
Plasma enhanced growth of GaN single crystalline layers from vapour phase,,"Gallium nitride (GaN) is a III-V semiconductor, characterized by direct, wide band gap of 3.4 eV at RT. As a material of particular interest for opto- and power electronics applications, it has been thoroughly studied in recent years. Utilization of GaN homoepitaxy in manufacturing of laser diodes (LDs), light-emitting diodes (LEDs), power devices, etc. would be beneficial in terms of reducing defect density, thus improving their lifetime and performance. Yet cost-effective process for providing native GaN substrates has not been established so far. The focus of this work is put on development of a new method to grow single crystalline GaN layers from Ga vapour. Our approach exploits microwave (MW) plasma as a source of excited nitrogen species, in contrast to classical physical vapour transport (PVT)-based technique, in which ammonia (NH3) serves as a source of reactive nitrogen. Novelty of MW plasma enhanced growth of GaN from vapour lies in MW nitrogen plasma formation in the vicinity of the seed, at moderate pressure (200 - 800 mbar range), and concurrent physical vapour transport of Ga to the growth zone. Simulations of the growth setup (HEpiGaN software) and of the MW plasma source (CST Microwave software) have followed the extensive investigations of material properties. The growth setup and the MW plasma source, with the resonance cavity being its crucial part, have been constructed and implemented into the existing growth reactor. The stability of MW plasma in function of temperature and pressure has been studied along with its influence on the seed temperature, and thus on the growth conditions. Furthermore, optical emission spectroscopy (OES) has been utilized for in-situ characterization of the growth atmosphere. Studies on the interaction of Ga vapour with the nitrogen discharge were interpreted on the basis of the level structure of lower excited states of Ga. Deposition experiments have been conducted, using sapphire seeds, GaN, AlN and AlGaN templates, while GaN single crystalline layers have been grown on sapphire and GaN templates. Characterization of GaN layers have been done by various methods, i.e. structure of layers by scanning electron microscopy (SEM), their composition by energy dispersive X-ray spectroscopy (EDX) and secondary ion mass spectrometry (SIMS), and crystal quality by high resolution X-ray diffraction (HRXRD). Results of the characterization together with outcome of OES measurements revealed importance of carbon for the sub-atmospheric MW plasma enhanced growth of GaN from vapour. In addition, this fact was confirmed by experiments in the setup with reduced carbon content. Possible routes for GaN synthesis have been discussed, with the most probable being CN-assisted GaN formation. While CN was detected in the plasma spectra, there was no evidence for the existence of GaN molecules in vapour phase.",,"Zwierz, Radoslaw",2014,,,OPUS4-3071,Dissertation
Climate and land use change impacts on water resources in the Lusatian river catchments (Germany) - Analysis and assessment considering modelling uncertainties,,"In anthropogenically heavily impacted river catchments, such as the Lusatian river catchments Spree and Schwarze Elster in Germany, the robust assessment of potential impacts of climate change on the regional water resources is of high relevance for water resources management. Large uncertainties inherent in future scenarios may, however, reduce the willingness of regional stakeholders to develop and implement suitable adaptation strategies to climate change. This thesis proposes the use of an integrated framework consisting of i) an ensemble based modelling approach and ii) the incorporation of measured and simulated meteorological and hydrological trends to consider uncertainties in climate change impact assessments. In addition, land use, as the most responsive catchment characteristic to buffer potential climate change impacts, is considered as one suitable trigger for climate change adaptation. The ensemble based modelling approach consists of the meteorological output of four climate downscaling approaches (DAs): two dynamical and two statistical. These DAs drive different model configurations of the two conceptually different hydrological models WaSiM ETH and HBV light. The objective of incorporating measured meteorological trends into the analysis was twofold: trends in measured time series can i) be regarded as harbinger for future change and ii) serve as a mean to validate the results of the DAs. In order to evaluate the nature of the trends, both gradual (Mann Kendall test) and step changes (Pettitt test) are considered as well as temporal and spatial correlations in the data. The suitability of land use change as an adaptation strategy to climate change is evaluated in the form of different land use change scenarios: i) extreme scenarios where the entire catchment is parameterised as coniferous forest and uncultivated land and ii) scenarios of changes in crop cultivation and ii) a combination of a change in crop cultivation and forest conversion. As study areas serve three almost natural subcatchments of the Spree and Schwarze Elster (Germany). The results of the ensemble based climate change impact analysis show that depending on the type (dynamical or statistical) of DA used, opposing trends in precipitation, actual evapotranspiration and discharge are simulated in the scenario period (2031 2060). While the statistical DAs simulate a decrease in future long term annual precipitation, the dynamical DAs simulate a tendency towards increasing precipitation. The trend analysis suggests that measured precipitation has not changed significantly during the period 1961 2006. Therefore, the strong decrease in precipitation simulated by the statistical DAs should be interpreted as a rather dry future scenario. The dynamical DAs, on the other hand, are too wet in the reference period and needed to be statistically bias corrected which destroys the physical consistency between the parameters. Concerning temperature, measured and simulated trends agree on a positive trend. The uncertainty related to the hydrological model within the climate change modelling chain is comparably low when long term averages are considered but increases during low flow events. The proposed framework of combining an ensemble based modelling approach with trend analysis on measurements is a promising approach to gain more confidence into the final results of climate change impact assessments and to obtain an increased process understanding of the interrelation between climate and water resources. In terms of climate change adaptation, land use alternatives can have a considerable impact on the water balance components as the analysis of the extreme scenarios revealed. The scenarios of changes in crop cultivation in combination with forest conversion show, however, that the impact on the long term annual water balance is comparably low. An intra annual shift in the water balance components can be triggered which makes these scenarios suitable to reduce low flow risks during the summer. Overall, land use change can serve as one part of an integrated climate change adaptation strategy. Such as strategy needs, depending on the severity of the climate change impact, to include other, especially technical measures of water resources management, such as additional water storage, different strategies to manage the existing and new reservoirs. It may also consider additional water transfers from neighbouring, more water rich, river catchments. Regional adaptation planning needs also to consider problems related to water quality which are a consequence of the long term mining activities in the Lusatian river catchments. Last but not least, adaptation strategies should not only consider climate but also other aspects of global change.",,"Gädeke, Anne",2014,,,OPUS4-3251,Dissertation
Community-based forest management and changing gender roles in a patriarchal society in Cameroon: The case of Korup and Bechati forest areas,,"Forest resources provide a means of livelihoods in rural communities in most developing countries. Growing threats of disappearance of these resources as a result of human and natural activities led Cameroon in 1994 to institute new forest policy reforms which amongst others aimed to formalize and strengthen the involvement of local communities in forest management. Although much has been written on the importance and methods of participation of the local people in sustainable forest management, little has been done to assess the involvement of especially women in forest management activities. This study aims to contribute to an understanding of the roles of indigenous men and women in forest management activities, how they are shaped by management regimes and the influence on their livelihoods. Results are based on empirical findings from two case studies-the Korup National Park Area (KNPA) and Bechati Forest Area (BFA). The analysis focuses on the different roles of men and women in forest activities, exploring how policies have influenced their participation. It further uses the concepts provided by gender analysis and SLF to check the potentials for improved participation of men and women in forest management and sustainable rural livelihoods. Results show that men and women in the research communities are solely dependent on forest resources for their livelihoods. They perform different roles with different interests and needs regarding the forest and its resources. Men and women have different responsibilities in protecting and maintaining homestead, common and forest lands. The results show that men are interested in cash crop production and usually own large plots and a greater proportion of women are involved in food crop production mostly for subsistence. The analysis of the management practices in both research areas show that formal and traditional ways of managing the forest are practiced. The traditional method is supplementary to the formal as the inability of traditional council to solve some forest problems are forwarded to the court of law where sanctions are taken. Considering that they are few guards to patrol the forest or visit the communities regularly would mean increase illegal activities in the forest. With some recognition, cooperation and mutual understanding between the local people, government and conservation staff, the management of the forest would be improved. The analysis further reveals clashing traditional, governmental and participatory management strategies leading to tensions, conflicts and lack of trust among actors. Results on gender analysis in research communities portray power relations in forest issues. Rights and access to natural resources like land, trees and animals is gendered. Land tenure rights BFA are hereditary and entitled to the male successor of the family. In KNPA, it is based on demarcation and occupation. However, though land acquisition is open to both men and women in the KNPA, women were found to acquire less land due to numerous responsibilities and lack of strength. The amount of land acquired determines the degree of authority a family or an individual possesses. The analysis also shows that there is some form of change in gender roles although women are not highly represented and even fewer women take part in decision-making processes. Gender issues are integrated in most policy commitments in Cameroon but if steps are not taken to translate them into practice, the increase participation of women in forest management will remain limited. True change can be achieved if decision-makers ensure an inclusive implementation of gender issues at all levels of project planning. A change in traditional attitudes on the roles of men and women should be adopted and a rethinking on policies (e.g. land tenure and property rights) is necessary to pave the way for greater female participation.",,"Nkengla, Lilian",2014,,,OPUS4-3340,Dissertation
"Potential, challenges and operation performance analysis of small business : with special reference to telecommunication components sector of the United States of America",,"The problems of small companies in the telecommunication components sector (signal processing components) have been and are the subject of many discussions and publications. In many cases, such companies have been started based on past results of ""experiments"" and failed, amongst other things, because of bad location. Poor location and poor operation management along with strong competition resulting in low sales are some reasons of the failures of small firms. In global markets, small firms are additionally forced to compete with their large counterparts and many other small ones. The newcomer to this field has to consider that it is useful to start with an elaborate strategy and to carefully implement this. Within the scope of this work the existing literature has been researched to find out successful methods to survive in the global market, which should be possible if there are clear ideas regarding the potential and challenges of small firms. The relevant literature is referenced and commented upon. Amongst others we found ""Michael Porter's Competitive Strategy"" (1980, The Free Press, New York). However his theory has only been applied to companies larger than 500 employees. He has identified two models we will use, the value chain model and the market forces model. In order to support these models, several performance indicators were tested, like market share, return on in investment (ROI), revenue per employee (RPE), value added (VA), value added at each stage of progressing will be equal to the total value of the product) and return on management (total revenue less total cost divided by total revenue). It is obvious from the literature review that individual performance measures not always need to convey the real performance of the firm. Objectives of the Study: From the foregoing discussion it is evident that the present study addresses itself to this task. To be more specific, the major objectives of the study are the following: 1. To analyze challenges and potential of small businesses regarding the industrial development of the U.S. 2. To analyze the factors influencing firm performance with special reference to the small telecommunication components companies of the U.S. In this context, organizational and financial factors, value chain factors and market forces are important. Research Questions of the Study: 1. To determine the opinions of the respondents on the impact of the operational and financial factors on the performance of small telecommunication components companies 2. Based on the opinions, determine whether the value chain factors play any role on the performance of small telecommunication components companies 3. Based on the opinions, determine whether the market forces have any impact on performance of small telecommunication components companies Conclusion: The main objective of the study was to examine the relationship between performances on the one hand and organizational and financial factors as well as value chain factors and market forces on the other hand. It is apparent from the above analysis that company performance is directly related to several organizational and financial factors. The relationship between small firm's performance and value chain factors is also evident from the analysis. Besides, small performance and market forces are closely related. This study empirically tested the application of Porter's market forces and value chain models in analyzing the influence of market forces and value chain factors on small firm performance. It was originally developed by Porter to analyze the influence of market forces and value chain factors on the performance of large businesses. The empirical analysis shows that these models can also be applied to small U.S. companies in the telecommunication components sector. Results of the study also indicate that composite performance index developed is a better measure than individual performance indicators.",,"Rohde, Christina S.",2014,,,OPUS4-3192,Dissertation
A knowledge discovery cycle for monitoring mobile cyber-physical systems,,"Mobile cyber-physical systems (MCPSs) such as motor vehicles, railed vehicles, aircraft, or spacecraft are commonly used in our life today. These systems are location-independent and embedded in a physical environment which is usually harsh and uncertain. MCPSs are equipped with a wide range of sensors that continuously produce sensor data streams. It is mandatory to process these data streams in an appropriate manner in order to satisfy different monitoring objectives, and it is anticipated that the complexity of MCPSs will continue to increase in the future. For instance, this includes the system description and the amount of data that must be processed. Accordingly, it is necessary to monitor these systems in order to provide reliability and to avoid critical damage. Monitoring is usually a semi-automatic process while human experts are responsible for consequent decisions. Thus, appropriate monitoring approaches are required to both provide a reasonably precise monitoring process and to reduce the complexity of the monitoring process itself. The contribution of the present thesis is threefold. First, a knowledge discovery cycle (KDC) has been developed, which aims to combine the research areas of knowledge discovery in databases and knowledge discovery from data streams to monitor MCPSs. The KDC is a cyclic process chain comprising an online subcycle and an offline subcycle. Second, a new data stream anomaly detection algorithm has been developed. Since it is necessary to identify a large number of system states automatically during operation, data stream anomaly detection becomes a key task for monitoring MCPSs. Third, the KDC and the anomaly detection algorithm have been prototypically implemented and a case study has been performed in a real world scenario relating to the ISS Colombus module.",,"Noack, Tino",2014,,,OPUS4-3367,Dissertation
"From ""Feudal Rubbish"" to ""National Treasure"": The transformation and safeguarding of intangible cultural heritage of China. A case study of Huanxian Daoqing Shadow Theatre",,"This study examines the history of the transformation of the intangible cultural heritage of China and the efforts to safeguard it, using the case study of Huanxian Daoqing shadow theatre. A regional style of Chinese shadow theatre, Daoqing has undergone dramatic transformation from 1949 to 2013, from being labeled in socialist China as a form of ""feudal rubbish"" to be eradicated, to being safeguarded as ""national treasure"". The changes in Daoqing's social identity, function, value, interpretation, transmission and safeguarding efforts can be observed in the discourses of both the authorities and the practicing community. These changes may be understood as part of three different stages in the political and economic transformation of socialist China. The researcher has collected governmental archives and conducted semi-structured interviews with Daoqing inheritors in an interpretative phenomenological analysis approach. This thesis analyses how, following Hobsbawm's argument, Daoqing as an intangible cultural heritage involves an ""invention of tradition"" through joint actions of the Chinese government and the Huanxian community. This research can help provide heritage policy makers, the community and other stakeholders with insights into challenges that may be faced in the safeguarding of the intangible cultural heritage. The theoretical framework, the methods and the research results from the government archives and interviews will hopefully serve to provide some new ideas as a prototypical approach to help future research on other forms of cultural heritage in China.",,"Liu, Chang",2014,,,OPUS4-3054,Dissertation
Detection and behavior of iron-cyanide complexes in soils of a former Manufactured Gas Plant site,,"Soils and groundwater on sites of the former Manufactured Gas Plants (MGPs) are contaminated with various complex iron-cyanides (Fe-CN). The aim of this thesis was to evaluate a new method for the CN detection and to investigate the stability and retardation of Fe-CN complexes in soils. This study seeks for enhancing the efficiency of phytoremediation as a proper approach to decontaminate Fe-CN complexes and thus tries to make a contribution to environmental protection. Feasibility of Field Portable Near Infrared (FP NIR) Spectrometry to determine CN concentrations in soil was evaluated in order to develop a rapid and non-destructive in-situ method. The study revealed that FP NIR could be a reliable device for detecting CN concentrations >2400 mg kg&#8722;1 in the field and >1750 mg kg&#8722;1 after sample preparation in the laboratory, however the limits of detection are too high to replace the traditional methods. The applicability of neutral solution extraction to determine the water soluble CN fraction and the stability of Prussian Blue under saturated and unsaturated water conditions was studied in a column and batch experiments. Study revealed continuous solubility of Prussian Blue, in acidic and slightly alkaline MGP soils. Dissolution of ferric ferrocyanide under circum-neutral pH and oxic water conditions was proposed to be a function of time, where the released amount is dependent on the soil pH and total CN content. Modeling the long-term release of Fe-CN complexes from the MGP soils revealed two-phase-process. The fast released phase was attributed to the transport process of readily dissolved hexacyanoferrats that is taking place in the liquid phase combined with desorption of CN bound to heterogeneous surfaces that are in direct contact with aqueous phase (outer-sphere complexation). The CN release rates increased with increasing pH, decreased with low initial CN concentration and were retarded by the increase in OM content. The retardation of Fe-CN in soil was investigated in batch and column experiments. Experiments revealed that the excess of the available iron, which induced the formation of the Prussian Blue colloids despite the circum-neutral pH, was a very important factor in decreasing the CN concentration. Additionally, despite the chemical factors influencing the potential reaction with manganese oxides, the physical factors like pore size distribution, variation in the grain size etc. can reduce the CN concentration due to mechanical retention of the vertical colloidal ferric ferrocyanide movement. This study proposes colloidal vertical transport of the solid Fr-CN complexes as a potential alternative process influencing the CN mobility in the circum-neutral pH and under the excess of available iron conditions. The results presented in this thesis revealed limitations of the FP, but advancing the sample pretreatment procedures can improve the feasibility of the spectrometer in detecting CN signal. Long-term extraction with the distilled water provides reliable assessment of the potential environmental hazard due to continuous dissolution of the solid Fe-CN complexes. Inconsistency of the Prussian Blue stability reported in the literature to the one obtained in this study imply usage of the CN contaminated MGP soils, instead of synthetic solutions, to advance the knowledge concerning the solid Fe-CN dissolution behavior. Furthermore, in the non-acidic soils the CN solubility might be influenced by the equilibrium with manganese Fe-CN mineral.",,"Sut, Magdalena Maria",2014,,,OPUS4-4063,Dissertation
Aluminium based micro mirrors exposed to UV laser light - in situ performance and degradation,,"The present thesis characterises aluminium based micro mirrors exposed to UV laser light. Such micro mirrors, used in highly integrated spatial light modulators, can for example be used as programmable masks in DUV micro lithography. Therefore they are sensitive to any performance loss arising from material degradation or changes in the mirror curvature. The key question addressed in this thesis is the investigation of the in situ curvature change, which means characterisation during a real laser irradiation. For this purpose a measuring station was designed, combining a phase-shift interferometer, an optical microscope and the laser irradiation of the sample at 248nm. The Phase-shift interferometry technique used is a very sensitive contactless optical measurement principle, which allows a resolution of the sample surface in the single-digit nanometer range. A multitude of irradiation tests were performed to describe the change of mirror curvature as a function of different irradiation parameters such as the pulse energy, the laser repetition rate or the ambient atmosphere. The most significant effect was detected by the variation of the applied pulse energy, which was in the range of 10&#8315;&#8309;J/cm²-10&#8315;²J/cm². A general conclusion was that a minimum energy of 10&#8315;&#8309;J/cm² at a repetition rate of 1kHz is required to detect any laser induced change of the mirror curvature. At higher energy levels two characteristic behaviours can be distinguished. Up to a level of 10&#8315;³J/cm² the mirrors show a permanent concave bowing in the range of &#955;/100. A further increase of the pulse energy causes an accumulating bowing in the opposite direction (convex) of &#955;/10 within some ten million laser pulses. However this convex bowing partially relaxes after the irradiation is stopped. Another aspect of the thesis was the determination of laser induced material degradation. For this purpose irradiated mirrors were investigated by means of different devices and analytical techniques such as atomic force microscopy (AFM), reflectometry and transmission electron microscopy (TEM). The AFM analysis showed a slight increase of surface roughness and a directional change of the grain size. As a result of the TEM analysis it turned out that arrangement and shape of the grains seems not to have changed. But after the irradiation the growth of a porous oxide layer up to 20nm on the upper mirror surface was noticed. Finally different hypotheses are proposed to explain the mechanisms behind the observed concave and convex bowing at particular pulse energies. In this connection it is assumed that the mirrors at pulse energies larger than 10&#8315;³J/cm² do not show a static bowing at all. It is rather assumed that the mirror bow oscillates with the laser repetition rate.",,"Mai, Alexander",2014,,,OPUS4-3149,Dissertation
"Heritage sites management : understanding the interrelation among heritage, tourism, and local community urban demands in Luxor City in Egypt",,"The global regulations and policies of the foundational UNESCO World Heritage (WH) are by far unable to solve the management threefold relationship conflicts between Heritage, Tourism activities, and urban needs as integral components of a Heritage site. Besides, fundamental scholars as well have not explored this existing relationship comprehensively. Instead, the conflict is discussed in a twofold manner. So, both existing international regulations and latest literature contributions have failed to understand the obstacles to bring out applicable on-site approaches for Heritage site management. This research provides a novel lens with which to understand the conflicting demands of Heritage sites management. It does not only delve into bringing forward the predominant reasons for failure particularly for Luxor city in Egypt as an overarching question, but also the long-term impact on Tourism management and society overall from an urban perspective. The key research questions are: (1) how definitions and conceptions of Heritage Value by foundational resources are reflected in the Tourism field; (2) how the Egyptian Heritage protection laws regulate the stated conflict; and (3) focusing on Luxor city, how the history of Tourism, Heritage policies, and urban planning in Egypt, which favoured tourism-oriented projects, impacted the morphology of the city and its urban and social networks. The investigation of Heritage Value definitions revealed a broad spectrum of views and even contradicting notions. The quandary nature of Value is evident in the Egyptian Heritage protection regulations. Additionally, they are not on the same pace as the international discourse about the complexity of Heritage protection. It viewed Value resources of Luxor city that were destinated for tourism-oriented development plans from the Heritage and Tourism points of view to come up with increasing concerns and unsolved plights. For realistic and sustainable Heritage management, the UNESCO WH Centre's insufficient relation to WH sites needs local community representatives as an equal third party instead of maintaining it primarily through experts from its Advisory Bodies and State Parties. Egyptian Heritage protection laws should be reformed to identify the urban context as an integral component of Heritage sites, provide the local communities with technical and financial incentives, and integrate Historic Urban Landscapes recommendations. Heritage sites management and urban planning of cities of Heritage Value in Egypt should be restructured to be on the local level, where the power and interest landscape of stakeholders are the most balanced. The regulatory reorganisations that acknowledge the broader urban milieu at the international, national and local levels are a chief factor for sustainable Heritage site management.",,"Hesham, Eman Shokry",2014,10.26127/BTUOpen-5274,,OPUS4-5274,Dissertation
Rural restructuring and conflicting definitions of the rural (problem) in East Germany,,"Rurality or ""rural life"" has not mattered much as a concept in public and political as well as scientific discourses during the 1990s. In recent years, it has experienced a remarkable resurgence. This paper tries to investigate this phenomenon. Therefore, major trajectories of rural change in East Germany since 1989 are briefly described, and rural discourses in selected policy arenas are explored. It is argued that the notion of rurality is differentiated across different discourse arenas. While the notions of rurality are not independent from each other, they do not form a coherent worldview. This fragmentation of rural discourses reflects the increasingly hybrid reconstitution of the global countryside. Paradoxically, the notions of rurality do not reflect this hybridity, but they mostly seem to remain in traditional ways of thinking and largely draw on widespread rural images of village, peasantry, cooperation and natural beauty. The resurgence of rurality in public debates is also an expression of a progressing German integration, in which the East-West divide and the narrative of post-socialist transformation are more and more replaced by new political agendas and new framings of problems and causal relations.",,"Laschewski, Lutz",2014,,,OPUS4-2881,Bericht
Decentralized Rural Electrification in Ghana-Evaluation of Technical and Socio-Economic Aspects for Sustainable Solutions,,"Rural electrification has been one of the challenges faced by the government of Ghana due to extremely high cost of electricity extension to the rural areas. In order to meet up this challenge, the government of Ghana has been keen with the introduction of renewable energy programs as a solution for rural electrification. However, most of programs are also faced with the problem of being sustainable. After government and sponsors hand-over completed project to local users, they usually last only few years of their life span and are abandoned. This challenge has inspired this study to identify the potential barriers to the sustainability of rural electrification programs through technical and socio-economic evaluation of a solar PV rural electrification project in Ghana. The approach of this study selected an on-going solar PV project (community solar system-CSS), that has been introduced on a pilot base across the whole of Ghana, which is to be adopted as a standard system for electrification solutions in rural areas in Ghana. This project was subjected to both technical and socio-economic evaluations covering 13 rural communities across the southern part of the country. Stakeholder interviews and review of literature were additional methodologies employed to gather information pertinent to the theme of the study. The results of the study show that technically, the CSS project has simple design and operational technologies, which gives it high integration potential. However, the project faces the problem of technology misuse by the rural users and frequent failure of its components. The socio-economic barriers identified are: (1) ineffective management of the project due to a long chain of bureaucratic administrative management system, inadequate monitoring and supervision, and inconsistency in standardizing the cash flow of the project, and (2) low electricity capacity of the CSS project and other similar small scale renewable projects to meet the electricity requirements of the rural populates. These problems lead to gradual decline of users' interest for such small scale renewable energy projects and subsequently result in project abandonment. It was concluded that small scale renewable energy programs lack the capacity to fully meet the energy requirement of rural populates; however, they are crucial as intervening solutions and play key role in rural development.",,"Acquah, Michael",2014,,,OPUS4-2999,Masterarbeit / Diplomarbeit
Effect of mining on regional climate,,"Intensive coal mining over the region of Lusatia covers a large area in southern Brandenburg and Saxony. Post mining this region has been filled with water resulting in lake formation. People living in the vicinity of mining area believe that the lake formation will increase convective precipitation in the neighboring area which shall lead to weathering of their structures. This was the prime reason to investigate the Lusatia region. The study about the impact of lake was carried out using data and CCLM simulation analyses. For data analysis, stations Senftenberg, Cottbus and Elsterheide-Geierswalde were selected. For the analysis, six 10 years running time series, CPDF were analyzed for all the three stations. Last three time series included the period of lake formation at station Elsterheide-Geierswalde. The CPDF time series showed little deviation for station Elsterheide-Geierswalde as compared to that for other two stations during lake formation periods. But in absence of parameters (temperature, wind data) data analysis was inconclusive. To observe effect of LULC (Land use and land cover) change on precipitation, three different simulations have been carried out, 1. VAT010: This simulation represents the potential vegetation of the whole domain. This describes the pre mining stage of the area when there was no mining. 2. VAT020: This simulation represents the introduction of lake points in the model domain. This describes the situation of area post mining, when lakes are formed.",,"Nawdiyal, Manish",2014,,,OPUS4-3463,Dissertation
Experimental investigation and CFD analysis of wind energy estimation considering building integrated ducts,,"Wind energy is a growing concern over the present awareness of lethal impact of green house gas emission. This energy source has been proven a promising alternative to fossil fuel based energy. Increased onshore wind capacity and decreased amount of low roughness wind sites has inspired the wind energy researchers to explore the possibilities of wind energy from high roughness sites such as urban area. Moreover, exhausted grid capacity between the wind energy producer from remote area and the consumer at city is also a major constrain for wind energy expansion. Driven by such motivation, this thesis has explored possibilities of wind energy conversion from buildings where energy is needed the most. Urban topography is known to be highly turbulent region considering its roughness characteristics. Wind energy yield from urban aerodynamics is a vast arena of experimental research. Within the time frame of the thesis period and available opportunities, a brief description about the wind energy assessment modelling approach from urban flow was outlined. There are several possibilities of wind energy yield from the built structure, but only building integrated duct was focused in this thesis. Time-averaged and global wind speed on the building integrated ducts, flow around the buildings was measured from wind tunnel and numerical analysis. Available wind energy yield and turbulence present in the locations measured from the flow was calculated based on the wind tunnel data and summarized with the pros and cons of the particular geometry. Elliptical duct configuration was found to achieve maximum energy yield from the omnidirectional free stream flow. However, simple rectangular duct configuration was determined as most efficient and optimized considering its simplicity, financial feasibility and relative energy yield with other duct configuration. The thesis also showed that on roof configuration is also very promising for wind energy exploration from the omnidirectional free stream flow. Necessary recommendations were made based on available result for future development of the research approach. Scope and opportunities was mentioned. This investigation has proved that it is possible to extract limited amount of wind energy from building augmented ducts using concentrator effect of the building exterior. Thus, the thesis concluded that the wind energy yield from building augmented ducts using the concentrator effect of the building exterior is a promising renewable energy source.",,"Hasanuzzaman, Gazi",2014,10.26127/BTUOpen-6192,,OPUS4-6192,Masterarbeit / Diplomarbeit
Arsenic contamination of groundwater in south-western part of Ashanti Region of Ghana,,"Groundwater samples were collected from 63 community wells and boreholes within south-western part of Ashanti Region of Ghana to examine their hydrogeochemical characteristics and elemental features to better understand the sources and mobilization processes responsible for arsenic (As) enrichment as well as the suitability of the groundwater for domestic and agricultural purposes. In addition, gold mine tailings dams were also investigated to ascertain the potential source of As and other trace metals (Fe, Cu, Mn, and Zn) contamination and their dissolution into the adjoining environmental media. Further, two point-of-use As removal technologies were evaluated for their effectiveness and appropriateness. A transparent small volume flow-through cell coupled with a calibrated hand held YSI® Multi-Parameter Water Quality Meter (Model YSI 6 l0-DM/600XL) was used simultaneously to measure indicator field parameters. Anions and cations were determined simultaneously in groundwater samples using Metrohm 761 Compact IC and Dionex 4500i IC system, respectively. Total As and trace metals analysis of the groundwater samples and gold mine tailings were performed on electrothermal and flame atomic absorption spectrometry. As speciation were performed using disposable cartridges. Spatial distribution maps were produced for hydrogen ion concentration (pH), total dissolved solids (TDS), total hardness (TH), electrical conductivity (EC), sodium adsorption ratio (SAR), residual sodium carbonate (RSC) and percentage sodium (% Na) using the geographic information system (GIS). Results for the analysis of groundwater samples from 63 boreholes and wells (depth 1.5-100 m) within the study area demonstrate that the groundwater composition varies from Ca-Mg-HCO3 to Na-K-HCO3 and anoxic in nature. As concentrations ranged from <0.1-72 µg/L and <0.1-83 µg/L during the dry and the wet seasons, respectively. High As concentrations were generally present in the shallow to medium depth (20-70 m) of the aquifer along with high Fe ranging from <0.01-12.3 mg/L and <0.01-16.3 mg/L during the dry and the wet seasons, respectively and relatively low Mn (1.8-498.0 µg/L during the dry season and 2.3-583.8 µg/L during the wet season). The data demonstrated that 59 % of the groundwater samples contained no detectable level of As, 17 and 22 % of the samples gave results with levels of As above the World Health Organization (WHO) guideline value for drinking water standard of 10.0 µg/L, while 24 and 19 % of the samples showed results below the WHO drinking water guideline value during the dry and the wet seasons, respectively. Dissolved inorganic As species predominate with arsenite (As-III) as the main form. It appears that high As concentrations in the study area result from the contribution of different mechanisms which can be grouped into two namely aquifers under oxidizing conditions (aided by sulphide alteration) and aquifers under reducing conditions resulting from the reduction dissolution of arseniferous iron oxyhydroxide that exist as a dispersed phase on the sedimentary grains of the aquifer. In addition, water residence time and different water use practices also influence As concentrations in the groundwater. The results of the gold mine tailings dam revealed elemental concentrations ranging up to 1752 mg/kg As, 75.16 wt.% Fe, 1848.12 mg/kg Mn, 92.17 mg/kg Cu and 177.56 mg/kg Zn. Sulphate was the dominant anion throughout the leachate, reaching a maximum dissolved concentration of 58.43 mg/L. The As concentration levels of the mine tailings were very much higher than the Netherlands soil protection guideline value of 55 mg/kg. A higher amount of the total As content in the mine tailings registered leaching levels in a range of 0.04-0.56 %. It was observed from the study that the groundwater was predominantly soft in nature and its pH in desirable range which is within safe limits for domestic use during the dry season while 82.8 % of the analyzed groundwater samples registered a non-desirable pH range (acidic) during the wet season. The results for the spatial distribution of pH, TDS, TH, EC, SAR, % Na and RSC of the groundwater samples analyzed generally appear to be within safe limits. The two point-of-use As removal technologies evaluated shown that the Three-earthen pot system is the most effective and appropriate technology. Moving forward, it is my anticipation that the findings of this study will serve as a master piece to advice policy makers, well and borehole owners about the dangers or potential risks associated with As and other trace metals in drinking water supplies sourced from groundwater and how these can be managed. In addition, this research has identified high-risk As-contaminated areas, potential health issues, methodology for assessing As in groundwater, and a broad outline of two point-of-use As treatment options which can target risk populations to protect public health and help shape the national, regional, municipal and districts water monitoring policies.",,"Bempah, Crentsil Kofi",2014,,,OPUS4-3196,Dissertation
"Architectural framework for dynamically adaptable multiprocessors regarding aging, fault tolerance, performance and power consumption",,"Despite the numerous benefits that Integrated Circuit (IC) technology downscaling brings, it also introduces many challenges. First of all, IC dependability is lowering: both lifetime reliability and resilience to single event effects is decreasing. Another major problem is the increased power consumption. On the other hand, the vast available space enables integrating hundreds of processor cores in a single chip! Multiprocessing is for over a decade the main architectural trend because of two reasons. Firstly, the performance of single processors gained by architectural innovations reached the upper limit i.e., the point of diminishing returns. Secondly, the operating frequency could not be increased due to the excessive power consumption, as pointed out. This work proposes a multiprocessor architectural framework that addresses many challenges related to dependability, power consumption and performance. The key idea is dynamical adaptation to the application requirements of fault tolerance and performance, which is possibly done at the lowest rates of aging and power dissipation. The application may select one of the three basic operating modes: de-stress, fault-tolerant and high-performance. De-stress mode prolongs multiprocessor lifetime and reduces power consumption by using core gating patterns that systematically power- or clock-off entire cores in the multiprocessor. These patterns use the information supplied by novel IC aging monitors. Fault-tolerant mode, on the other hand, increases error resilience by forming core-level NMR (N-modular redundant) systems using the multiprocessor cores. That is, entire cores are tightly synchronized to execute the same task simultaneously. Voting is done on each clock cycle using special, programmable NMR voters. Core-level NMR enables masking faults without invoking recovery procedures which is appreciated by timing-critical, or, real-time applications. Finally, high-performance mode is used for boosting multiprocessor performance. The framework is evaluated using a novel environment for automated fault injection, as well as a novel multiprocessor verification platform. A vast number of experiments were made which led to closed-form expressions that determine the number of cores N required to survive the projected mission time, given the fault rate. Moreover, a newly-developed method for lifetime evaluation based on the Weibul distribution shows the benefits of using core gating patterns. E.g., the new Youngest-First Round-Robin (YFRR) pattern enables up to 31% increase in system's lifetime compared to a simple Round-Robin.",,"Simevski, Aleksandar",2014,,,OPUS4-3257,Dissertation
13th EEEIC International Conference on Environment and Electrical Engineering - Student Edition : Wroc&#322;aw-Ostrava-Cottbus 19th - 23rd of May 2014,,"In the time of increased awareness about the environment problems by the public opinion and also intensive international efforts to reduce emissions of greenhouse gases, as well increase of the generation of electrical energy to facilitate industrial growth, the conference offers broad contribution towards achieving the goals of diversification and sustainable development. Focus of the student conference is to promote the discussion of views from scientists and students from Wroclaw University of Technology, Technical University of Ostrava and Brandenburg Technical University of Cottbus. The conference offers prominent academics and industrial practitioners from all over the world the forum for discussion about the future of electrical energy and environmental issues and presents a base for identifying directions for continuation of research.",,,2014,,,OPUS4-5677,Konferenzveröffentlichung
13th EEEIC International Conference on Environment and Electrical Engineering - Student Edition : Wroc&#322;aw-Ostrava-Cottbus 19th - 23rd of May 2014,,"In the time of increased awareness about the environment problems by the public opinion and also intensive international efforts to reduce emissions of greenhouse gases, as well increase of the generation of electrical energy to facilitate industrial growth, the conference offers broad contribution towards achieving the goals of diversification and sustainable development. Focus of the student conference is to promote the discussion of views from scientists and students from Wroclaw University of Technology, Technical University of Ostrava and Brandenburg Technical University of Cottbus. The conference offers prominent academics and industrial practitioners from all over the world the forum for discussion about the future of electrical energy and environmental issues and presents a base for identifying directions for continuation of research.",,,2014,,,OPUS4-4266,Konferenzveröffentlichung
In-operando hard X-ray photoelectron spectroscopy study on the resistive switching physics of HfO2-based RRAM,,"Current memory technologies, such as DRAM, SRAM, and NAND Flash, which are approaching very difficult issues related to the continuous scaling to and beyond the 16 nm generation, has led research over the past two decades to the discovery of several new memory technologies. In recent years, new emerging nonvolatile memories (NVMs), such as phase-change random access memory (PCRAM), ferroelectric random access memory (FRAM), magnetic random access memory (MRAM), and resistive random access memory (RRAM), have been intensively studied. Among these candidates, RRAM is a very promising and worldwide studied candidate for alternative NVM and a high potential successor for Flash in terms of energy consumption (write current in the &#956;A range compared to mA) and simplicity of process integration. A fully CMOS compatible TiN/Ti/HfO2/TiN RRAM module was successfully integrated with a select transistor (1T1R memory) in IHP's technology. Nonetheless, reliability and insufficient understanding of the resistive switching mechanism are the two main issues limiting this memory technology development for e.g. wireless sensor network (WSN) applications. The still unclear atomic-scale mechanism of HfO2-based resistive switches and the identification of the material changes within the insulator must be addressed to suggest a knowledge-based improvement of device performance. In this frame, the Ti/HfO2 interface is thoroughly investigated in this Thesis by complementary materials science techniques. First, the investigation of the as-deposited Ti/HfO2/TiN cells revealed that: (1) the Ti layer scavenges oxygen atoms stronger from amorphous (a-HfO2) than from monoclinic (m-HfO2) HfO2 films; (2) not only oxygen vacancies but also other impurities in the atomic vapor deposited (AVD) a-HfO2 film, such like nitrogen and carbon (probably resulting from the used AVD precursor chemistry) are present in the HfO2 insulator. Next, the electrical characterization of Ti/AVD a-HfO2/TiN cells (with voltage applied to the Ti top electrode while TiN bottom electrode was grounded) revealed a clockwise bipolar resistive switching behavior after an electroforming process at positive voltage polarity. Besides, the chemical and electronic changes observed by hard X-ray photoelectron spectroscopy (HAXPES), indicate the creation of n-type dopants in the a-HfO2 film during the electroforming process, probably related to the formation of positively charged oxygen vacancies in a-HfO2 by the electrochemically induced Ti/a-HfO2 interface oxidation. In order to directly compare electrical with electronic and chemical changes of one and the same RRAM cell, an in-operando HAXPES technique was developed. These unique studies have revealed the following characteristics of the Ti/AVD a-HfO2/TiN cells: (1) the as-deposited cells are able to switch at low electrical power; (2) However, this resistive switching is not stable and an electroforming process with a slightly increased power is required to stabilize the switching event; (3) Electrical changes correlated with HAXPES results and literature indicate that (i) the forming/set electrical power defines the oxygen vacancies concentration in the a-HfO2 and thus the stability of the resistive switching properties and (ii) the stable resistive switching can be described by a push-pull model of oxygen vacancies migration under the influence of an electrical field; (4) Besides, carbon segregation at the Ti/a-HfO2 interface - while increasing the electrical power or cycling the device - shows that the defects physics is not limited only to oxygen vacancies; other defects may thus contribute under electrical stress to the resistive switching phenomenon and need to be included in theoretical models to correctly describe the switching characteristics. Finally, according to the presented HAXPES results, the Ti/AVD a-HfO2/TiN RRAM cells are classified to the valence change mechanism. The resistive switching mechanism is attributed to the creation and rupture of oxygen vacancies-based conducting filaments and the Ti/HfO2 interface oxidation is of central importance for the defect balance of the RRAM cell. Most importantly, a reduction of carbon content in the AVD-deposited HfO2 improved the reliability of these memory cells.",,"Sowinska, Malgorzata",2014,,,OPUS4-3007,Dissertation
Mechanisms of carbide precipitation and carbon solubility in high Nb containing TiAl Alloys,,"TiAl alloys with a high addition of Nb have recently been applied in the aerospace and automotive fields due to their excellent high-temperature properties. The C additions to TiAl alloys have been reported to improve their strength and creep resistance through solid-solution hardening and / or precipitation hardening. In this work powder metallurgy (PM) based Ti-45Al-5Nb-xC (x=0, 0.5 0.75 and 1.0 at. %) alloys were systematically investigated after different heat treatments. The research is mainly concerned with the temperature range from 800 to 1000ºC which is interesting for processing as well as applications. The results show that the addition of C influences the phase transformations in Ti-45Al-5Nb and that the addition of Nb may influence the carbon solubility in TiAl alloys at high temperatures. The carbon solubility in Ti-45Al-5Nb is > 1.0 at. % at 1400°C, but between 0.5 and 0.75 at. % at 1000°C, and less than 0.5 at. % at 800°C. The carbide precipitation and development of carbide morphology are discussed in great detail. The thermal stability of P-Ti3AlC carbides in Ti-45Al-5Nb-xC alloys is increased, which might be attributed to the addition of high amounts of Nb, or the high amount of carbon, or a combination of both. In heat-treated Ti-45Al-5Nb-0.5C and Ti-45Al-5Nb-0.75C, H-type carbides are not detected to form during annealing. The addition of Nb may increase the formation temperature of the H-Ti2AlC precipitate phase.",,"Wang, Li",2014,,,OPUS4-3039,Dissertation
Development of creep resistant titanium aluminide alloys for the Metal Injection Moulding process,,"Titanium aluminides show great technological potential due to their light weight and excellent creep resistance. Their utilisation thus offers a potential to decrease fuel consumption and simultaneously improve the performance of components subjected to stress at high temperatures. However, shaping of titanium aluminides is still a very challenging and costly task considering their brittleness and the sensitivity on chemical composition. Therefore powder metallurgy near-net shape manufacturing techniques are very attractive to decrease material waste and reduce overall processing costs. This research work was focused on the preparation, characterisation and optimisation of creep resistant titanium aluminides for the Metal Injection Moulding (MIM) process. Considering the little information available regarding processing of titanium aluminides by MIM, this work had firstly the goal of assessing the creep behaviour of a reference titanium aluminide alloy. Secondly, alloy variations with compositions based on the reference material were designed with the objective of improving the creep resistance, especially concerning primary creep. The basic strengthening mechanisms applied involved the addition of slow diffusing elements and elements that cause precipitation of hard particles. The specimens were prepared by using pre-alloyed powder and mixtures of a master alloy (pre-alloyed) and elemental powders. Consequently, a great deal of effort was spent in the characterisation of the sintering behaviour in order to achieve reliable test pieces. Even though both methods can deliver sound specimens, the pre-alloyed powder approach led to the best results in terms of residual porosity and microstructural homogeneity. The mechanical testing results indicate that processing of titanium aluminides by MIM is feasible and acceptable creep properties can be achieved with the proper sintering parameters. Even though the ductility at room temperature was considerably limited due to the residual porosity and high amounts of impurities intrinsic to the MIM process, alloys developed within this study showed improved primary creep resistance in the high stress - high temperature regime. In particular alloy variations containing additions of Mo, Si and Gd led to a considerable improvement of the primary creep resistance in comparison to the reference material at 800°C - 350 MPa loading.",,"Soyama, Juliano",2014,,,OPUS4-3161,Dissertation
Optimal design of 245kV SF&#8326; bushing by using genetic algorithm,,"Currently more and more researches of high voltage bushings are focused on the requirements for a simple structure, compactness and light-weight. The general operation of SF6 gas-filled bushings (SF6 bushings) is satisfying the requirements, but in the operation and design of SF6 bushings still many improvements may be possible. The minimizing of dimension might enhance the electric field strength (E) on the crucial points of bushings, which may lead to partial discharge, flashover and even break down. Electric field distribution along the surface mainly depends on contour design, besides the effect of contamination. This dissertation mainly describes the optimization of the bushings design by genetic algorithm. First, a model of SF6 bushing was developed and simulated for the theory purpose. Then, the potential breakdown problems were defined and the mechanisms of the potential breakdown were explained. Afterwards, the dissertation proposes an approach, i.e. genetic algorithm to optimize the contour design of SF6 bushings. The approach improved the execution efficiency by accessing the fitness values of searched solutions during the optimization process. To verify the effectiveness of the genetic algorithm, it has been applied to minimize the electric field strength at the critical positions. Furthermore, the critical points of SF6 bushings were optimized. Several new structures of the ground electrode were proposed and optimized separately by genetic algorithm. A new curve, i.e. cubic spline was applied to the contour of the top flange to avoid the influence of the triple points. By optimization E on the surface of top flange was minimized. The potential distribution on the surface of insulator was optimized by a new structure. By the genetic algorithm the contour of composite weather sheds (WS) was optimized as water-drop form. In summary, a more uniform potential distribution along the surface of weather sheds and minimal values of electric field strength at critical points can be derived effectively by genetic algorithm. In addition, a smaller dimension of SF6 bushing was obtained in comparison with presently available ones.",,"Bao, Han",2014,,,OPUS4-3175,Dissertation
A tracking ADC with transient-driven self-clocking for digital DC-DC converters,,"With further scaling of CMOS technology noise disturbance, mismatch and process variation become the major constraints of analog DC-DC converters. Consequently, digitally assisted DC-DC converters are coming in the focus of new systems, because they are easier to be configurated in the applications than the typical analog DC-DC converters, while being more robust against noise disturbance and process variation. As interface devices between analog real world and digital signal processing, ADCs must be optimized for signals in digital DC-DC converters. But the existing synchronous ADCs, which require multiple clock cycles per conversion, as SAR and Pipeline ADCs, are not suitable for the application in DC-DC converters because of special signal characteristics. For stability reasons the digital feedback control in DC-DC converters requires a short group delay (dead time). So synchronous ADCs must be run at a sampling frequency as high as possible. But this approach results unfortunately in high power dissipation. Compared to the above mentioned ADCs, the delta-encoded or Tracking ADC exhibits the shortest group delay by performing the data conversion only in one clock cycle. It makes the digital feedback control of DC-DC converters possible to response the output exactly and simultaneously. However, the synchronized Tracking ADC still has to cover the double of broad signal bandwidth of disturbance, which appears at the output of DC-DC converters occasionally, dissipating unnecessary excessive power. This dissertation presents a new concept of Tracking ADC that selfadjusts the conversion rate depending on the slope of the input signal. For a slowly varying input, this Tracking ADC is self-clocked at a low frequency in normal mode, but once the signal varies fast and the slope exceeds a defined threshold, the conversion rate of the ADC is increased to track the signal accurately. By using the proposed solution not only the issue of input slope overload for typical Tracking ADCs is significantly improved, but also the average sampling rate is decreased. Therefore, the power dissipation of the proposed ADC is also reduced. As a proof of this concept, a 6-bit Tracking ADC with transient-driven self-clocking is implemented in 0.13&#956;m CMOS technology. The prototype of the ADC occupies an area of 400&#956;m×200&#956;m. The maximum power dissipation is 84&#956;W at a supply voltage of 1.4V, when operated at 50MS/s. The integral nonlinearity (INL) is better than 0.5LSB, and the effective number of bits (ENOB) at the sampling frequency of 12.5MHz is 4.4 bits, where the ideal ENOB is limited to 5 bits for 6-bit Tracking ADCs.",,"Huang, Yan",2014,,,OPUS4-3178,Dissertation
A methodology for designing low power sensor node hardware systems,,"The design of embedded sensor node hardware systems is a challenging task driven by the increasing demands for low power, high efficiency, low cost and small size. These unique requirements make the usage of off-the-shelf general purpose microcontrollers fairly inefficient. For many wireless sensor network applications, the design of a dedicated low power sensor node microcontroller is the only way to answer specific application requirements. According to the trends in device, process and design technology, the development of sensor node devices is relying on a cheap planar bulk-CMOS technology, where power consumption is dominated by static power loss caused by high leakage currents. To keep the power at acceptable level, designers are compelled to apply the methodologies based on advanced low power techniques that target both static and dynamic power in the chip. The decisions made early in design phase are likely to determine the energy efficiency of the final design. Therefore, the choice of power saving strategy is the key challenge in designing energy-efficient sensor node hardware. This work presents a methodology that assists designers meeting the critical design decisions regarding power, early in the design process. The presented methodology extracts the activity profiles of single system components and applies them in the developed models for energy estimation of particular low power implementation. The energy estimation models account for the energy overhead introduced by specific low power techniques, enabling comprehensive exploration of system's energy efficiency in a given application scenario. Special attention is paid to the methodology utilization in typical wireless sensor network applications. Accordingly, the examples of activity profiling in wireless sensor node systems are presented. The proposed methodology is integrated within a power-driven design flow and applied to the design of an embedded sensor node microcontroller. This methodology is used to perform the cross comparison of alternative low power implementations for the target system architecture. The implementation relying on concurrent clock and power gating is selected as the most energy efficient and consequently realised. Power switching cells and power control logic have been designed and characterized. Also, the final system architecture, basic system components and applied design process are described. Finally, the developed power-gated sensor node microcontroller is implemented, fabricated and successfully tested. The chip measurements results are presented and analyzed. The analysis of different low power approaches applied to the target system architecture has shown large impact of clock gating on the system energy. In a given application scenario, the clock gating implementation has reduced 72 times the dynamic energy and 12 times the total energy of the system. The implementation of power gating technique has gained 2.8 times reduction of the leakage energy and 2 times reduction of the total system energy compared to the clock gating only implementation. The analysis of two alternative power gating approaches has emphasized the significance of partitioning in power-gated design. A heuristic partitioning that combines two specific blocks having successive activity phases into a single power domain, thereby reducing design complexity and chip area, has been shown to have positive impact on the energy efficiency of the target design.",,"Pani&#263;, Goran",2014,,,OPUS4-3337,Dissertation
Cycle bases of graphs and spanning trees with many leaves - complexity results on planar and regular graphs,,"A cycle basis of a graph is a basis of its cycle space, the vector space which is spanned by the cycles of the graph. Practical applications for cycle bases are for example the optimization of periodic timetables, electrical engineering, and chemistry. Often, cycle bases belong to the input of algorithms concerning these fields. In these cases, the running time of the algorithm can depend on the size of the given cycle basis. In this thesis, we study the complexity of finding minimum cycle bases of several types on different graph classes. As a main result, we show that the problem of minimizing strictly fundamental cycle bases on planar graphs is NP-complete. We also give a similarly structured proof for problem of finding a maximum leaf spanning tree on the very restricted class of cubic planar graphs. Additionally, we show that this problem is APX-complete on k-regular graphs for odd k greater than 3. Furthermore, we classify types of robust cycle bases and study their relationship to fundamental cycle bases.",,"Reich, Alexander",2014,,,OPUS4-2966,Dissertation
"Occurrence and life-cycle strategies of bloom-forming Nostocales (cyanobacteria) in deep lakes in Northern Germany and in Lake Kinneret, Israel",,"Nostocalean cyanobacteria differentiate heterocysts to fix dissolved nitrogen (N2) and dormant cells (akinetes) to survive harsh environmental conditions. The distribution and proliferation of Nostocales and their hibernation strategies in deep stratified lakes of different trophic states and climate zones were investigated. Studies were carried out in the meso-eutrophic Lake Kinneret (Israel) and in the mesotrophic Lake Scharmützelsee and the oligo-mesotrophic Lake Stechlinsee (Germany). The spatio-temporal distribution of akinetes in sediments was analysed. The abundance in the sediment surface increased with water depth and differed due to basin morphometry. Light and temperature distribution revealed shallow areas of sedimentary akinete pool as a potential inoculum to contribute to the formation of a pelagic population. Hence, a small viable akinete pool was deposited in shallow sediments. A CARD-FISH protocol was implemented to identify and quantify the akinetes in sediments. Tested Nostocales strains and akinetes in sediment samples were successfully labelled with 16S rRNA targeted probes and microscopically detected by their fluorescence signal. Akinete enumeration in field samples confirmed the suitability of the CARD-FISH approach. Species- or genus-specific differences in the overwintering strategies of Nostocales were observed. Akinetes were the only overwintering form of Anabaena spp. On the other hand, Aphanizomenon flos-aquae overwintered as vegetative filaments in the pelagial of Lake Stechlinsee. In the other lakes studied, Aphanizomenon spp. performed an intermediate life cycle, with akinetes and a small pelagic population in winter. This suggested that Aphanizomenon spp. had another overwintering strategy contrary to the exclusively dormant strategy of Anabaena spp. Putative strains of cylindrospermopsin (CYN)-producing Aphanizomenon ovalisporum were isolated from Lake Kinneret. Their morphologic and phylogenetic diversity, as well as the presence of CYN-encoding gene cluster and CYN production, were analysed. Four of the six strains were assigned to Anabaena bergii. Although all the isolated strains possess at least fragments of CYN gene cluster, no CYN production was detected. Non-CYN-producing Aphanizomenon ovalisporum strains and the presence of non-toxic Anabaena bergii in Lake Kinneret have not been reported before. This suggested that toxic and non-toxic Nostocales strains can coexist in lakes.",,"Ramm, Jessica",2014,,,OPUS4-3172,Dissertation
Self-testing and self-repairing embedded processors: techniques for statically scheduled superscalar architectures,,"This thesis introduces a comprehensive approach for making a particular class of embedded processors self-testing and self-repairing, such that a limited amount of permanent hardware faults that occur during the lifetime of these processors in the field will not prohibit the functional behavior of the user application running on the processor. The presented concepts all use redundant hardware, but the techniques used for administrating the hardware-redundancy range from hardware-based methods over hybrid methods to pure software-based methods, whereby the focus is on the latter ones. The proposed methods will be demonstrated by using a processor that is well designed for diagnostic self-test and self-repair purposes. This will also highlight some architectural properties of such a processor, which are beneficial for performing a software-based self-test and self-repair process. Chapter 1 is an introduction to the field of dependable systems and fault tolerance. Fundamental terms and notations, which are used throughout this thesis for classification and evaluation, are provided. The used processor model - the VARP processor - is introduced in chapter 2 together with a hardware-based self-repair scheme for that processor. The results are used as reference values for evaluating the software-based methods. Chapter 3 introduces the fundamental concept of the software-based self-repair. In chapter 4 hybrid methods are derived by combining software-based and hardware-based methods, highlighting the synergy effects of the combination. Finally, in chapter 5, a diagnostic and adaptive software-based self-test scheme is introduced. This self-test scheme provides the diagnostic capability that is needed in the field for identifying defect components in the VARP processor and completes the comprehensive software-based self-test and self-repair approach.",,"Schölzel, Mario",2014,,,OPUS4-3126,Habilitation
Stochastic simulation efficiency,,"The work described in this report can be broadly divided into two sections. The first section considers two export features. We describe how the export for stochastic Petri nets to SBML level 1 has been added to the Petri net modelling and simulation tool Snoopy. This task was accomplished by making appropriate changes to the existing export code to generate SBML level 2. Also we demonstrate in detail, how the direct export for coloured Petri nets to both levels (i.e. 1 and 2) of SBML was realised. The next section summarises the performed comparison of different stochastic simulation tools for biochemical reaction networks. We first compare BioNetGen and SSC with each other by performing simulations on non-coloured Petri nets. Then, we compare the remaining four tools, i.e. Cain, Marcie, Snoopy and Stochkit with each other by performing simulation on coloured Petri nets. This work builds on results by Aman Sinha [19].",,"Swapnil, Chiru",2014,,,OPUS4-3147,Bericht
Investigation of methods for increasing the reliability of highly integrated non-volatile memories on system level,,"Conventional semiconductor memories are facing many challenges concerning their yield, reliability, testability, and manufacturability as the feature size decreases. Although they are used in the vast majority of electronic devices, their applicability for upcoming digital systems is questionable. On the other hand, due to unprecedented development of mobile devices even faster, denser, and more power-efficient semiconductor memories are required. As a consequence, many researchers and system designers are seeking new memory solutions. The greatest attention is paid to solid-state, non-volatile memories (NVMs) such as PCRAMs, MRAMs/STT-MRAMs, FeRAMs, and RRAMs. Due to their promising features like non-volatility, low-power consumption, and great scalability they are expected to meet the challenging demands of future digital systems. Unfortunately, despite all advantages they offer, emerging NVMs pose some peculiar characteristics like limited endurance, variable data retention time, or vulnerability to external factors. On top of that, they are still in early-maturity state where their fabrication processes are not of high quality and are prone to high variations. Because of that, emerging NVMs may suffer from permanent faults which can occur right after production or in the field, during their operational time. As a consequence, the reliability of new memory technologies requires special management and great improvement. The thesis introduces system-level approach aimed at comprehensive reliability management of existing and emerging NVMs. It presents novel on-line repair techniques which focus on specific issues of NVMs. The block-level repair manages post-production faults in the memory array. The word-level repair aims at hard faults caused by wear-out memory cells. Finally, the error-correcting code with increased hard-error correction capability handles soft and hard errors in the memory array. Because proposed techniques are based on similar principles, they can be combined into a consistent system. Depending on the way how they are connected, different repair schemes can be achieved. Moreover, by merging them into the system a synergistic effect can be produced where the achieved memory reliability improvement is greater than the sum of reliability improvements achieved with their standalone implementations. Further in the thesis, such a consistent repair system is presented. Next, its effectiveness, repair capabilities, and applicability for an embedded system are evaluated. In addition, the achieved synergistic effect is described and quantified",,"Skoncej, Patryk",2014,,,OPUS4-3512,Dissertation
Determination of specific metabolic activities of anammox bacteria and their sensitivity to oxygen,,"The discovery of Anammox bacteria has bridged our knowledge gap in the nitrogen cycle. This is because it explained the direct conversion of nitrite and ammonium to nitrogen gas in many reducing natural environments. However, it has been found that the presence of oxygen is an important determinat factor for certain biochemical processes and distribution of organisms in the environment. In this work, two methodological approaches were used to investigate the specific metabolic activities of Anammox bacteria and their sensitivity to oxygen using a mixed biomass culture. Two laboratory-scale bioreactors were maintained and the biomass in the reactors served as the inoculum for the investigations. The molecular characterization of the biomass was done using the Fluorescence in situ hybridization (FISH) technique. The specific Anammox activity (SAA) and important inhibition kinetic parameter characterization were estimated while monitoring activities of the biomass using several batch experiments. The results of the biochemical characterization revealed that several microbial activities such as denitrification, nitrification, dissimilatory nitrate reduction to ammonium and Anammox processes were competing in the bioreactors. These were observed in the analysis of effluent recirculation of the feed solutions in the bioreactors, however, the Anammox process was predominant. An optimum sonication time top of eight minutes was established used to determine the average optical density to dry mass (OD: DM) ratio of 0.87 in the biomass. The FISH characterization estimated 60.4 % ± 14.6% (mean ± standard deviation) Anammox bacteria concentration in the biomass of Bioreactor 1. The Anammox bacteria were made up C. Kuenenia Stuttgartiensis (&#820; 78%) and the remaining C. Brocadia Fulgida. The maximum SAA of 0.025 mgNH4-N (TSSAnammox-1. d-1) and 5.4 mgNH4-N (1011 CellAnammox-1. d-1) for ammonium, and 0.04 mg N2-N (TSSAnammox-1. d-1) and 9.4 mgN2-N (1011 CellAnammox-1. d-1) for nitrogen gas were found in the biomass. While a binding affinity constant Ki = 0.07 mgO2 /l, maximum half inhibition concentration IC50 &#820; 0.2 mg O2 /l and KM = 50 mg/l were estimated for the inhibition kinetics of oxygen in the biomass. The low Ki value found in this study indicates that oxygen is an efficient inhibitor for Anammox activities and concentrations between 0.4 - 0.64 mg O2 /l can lead to complete inhibition of Anammox activity. However, this process is reversible. Finally, the implication of this inhibition kinetic results might be important in tracing the distribution of Anammox processes in natural environments where fixed nitrogen is present.",,"Ijioma, Uche",2013,10.26127/BTUOpen-5582,,OPUS4-5582,Masterarbeit / Diplomarbeit
Development and pilot application of a measurement and benchmarking method for the sustainable consumption of household information and communication technology appliances,,"The rapidly developed Information and Communication Technology (ICT) products have made great contributions in various application areas. However, the related problems in the consumption of household ICT appliances are crucial to economy, environment and society. As concluded from literature review of practice, assessment and legislation, there is obvious lack of information and understanding of the household consumption pattern of the ICT appliance in a more systematic ""life-cycle thinking"" approach - from purchase, usage to end-of-life, in environmental-social- economic three dimensional perspective. This deficiency could lead to ineffective policy programmes and implementation. This exploratory study tentatively develops a measurement and benchmarking method, named as Sustainable Consumption Index (SCIndex) model, aiming at improving knowledge and holistic understanding of consumption patterns of household ICT appliances along the value chain in global or regional consumers' households. This dissertation accomplishes the preliminary design of the SCIndex model and its pilot application with a global Internet survey on consumer behavior for detailed analysis, such as, cross-cultural comparison, three stages analysis (purchase, usage and end-of- life), and total SCIndex score benchmarking and analysis. This study identified that overall consumption patterns of household ICT appliances in the developed countries are not necessarily more sustainable than in the developing countries, if all the stages of consumption are overviewed. The findings contribute to the gaps in knowledge of underlying behavioral factors that influence sustainable consumption of household ICT appliances entirely or in any stage; furthermore, they sketch out the national profiles and improvable aspects on the path of more sustainable consumption. The SCIndex model and pilot application stress the importance and provide empirical evidence to support concrete modelling with a multifaceted approach in measurement and benchmarking of household ICT appliances' life-cycle consumption for ""going beyond GDP"". The model is suggested to be optimized in sampling, design and structure, data analysis methods and the implementation. To efficiently promote sustainable consumption of the household ICT appliances, the pilot application provides further recommendations to the engaged stakeholders that include: i) sufficiency in purchase; ii) efficient usage; iii) responsible disposal; iv) smooth channels for reuse; v) further in-depth researches and projects.",,"Li, Juan",2013,,,OPUS4-3174,Dissertation
Climatic change impacts on subsistence agriculture in the Sudano-Sahel Zone of Cameroon - constraints and opportunities for adaptation,,"Unlike many areas of the world where agricultural producers exhibit the physical, economic and social resources to moderate, or adapt, subsistence agriculture in the Sudano-Sahel region of Cameroon is seem to be particularly vulnerable to the impacts of climatic variability. This is in part due to the fact that the majority of the population depends on rain-fed agriculture for their livelihood. Adapting to climate change in the subsistence agricultural sector is therefore very imperative in providing food security and concomitantly protecting the livelihood of rural communities. This study examined the patterns of current climatic variables on some selected subsistence staple crops namely; millet and sorghum in the Cameroon´s Sudano-Sahel. It also valorized and documented the community based adaptation strategies used by local farmers to cope with current climate change, explored the constraints and opportunities in adaptation and mitigation that could facilely be integrated and incorporated into policies and programs. The guiding premises were that climatic change impacts subsistence crop yields as the lower the rainfall, the higher the vulnerability of the yields of staple crops. It also hypothesized that the present community-based strategies used by the local farmers are relevant and crucial to the present day quest for climate change adaptation strategies. Analyses of agricultural droughts using the Standardized Precipitation Index (SPI), spatio-temporal land use and land cover dynamics via remote sensing were utilized as well as the application of statistical tools for the investigation of pressure and state indicators. A participatory research approach was used in exploring adaptation patterns perceived by the ruralites in the face of variable climatic condition via administered questionnaires. The results suggested critical impact asymmetries due to climatic and socio-economic factors affected subsistence crops in the Sudano-Sahel of Cameroon. Furthermore, SPI results indicated incidences of droughts; with the Multilinear Regression (MLR) models showing temperature and rainfall to an extent determined agricultural crop productivity in the Sudano-Sahel. However, other factors such as population growth have undoubtedly caused enormous impacts on the agricultural system as seen in remote sensing analyses. Questionnaire survey findings also connoted that subsistence farming communities have a rich repertoire of strategies ranging from changing of planting dates, changing of crop varieties, switching from crops to livestock, use of local indicators, movement from rural to urban areas, increment in cultivated lands, irrigation soil conservation practices among many others as they perceive varying climatic conditions. Additionally, some of these indigenous strategies are inherent in ecological agricultural practices that offer a win-win scenario for the simultaneously tackling of climate change adaptation and mitigation and hence meeting the development goals. The results further highlighted the lack of money, poor access to climate information, the encroachment of desert and shortage of man power as some of the factors hindering subsistence farmers' ability to adapt. The study concluded that adaptation measures in subsistence agriculture were highly significant for poverty reduction, thus improving on the well-being of the ruralites. The key to the ability of farmers to adapt would be access to relevant knowledge and information. Following the rich repertoire of strategies by local farmers, adaptation needed to be mainstreamed and institutional networks strengthened in order for effective community based adaptation. &#8195;",,"Techoro, Prosper Somah",2013,,,OPUS4-2750,Dissertation
Characterisation and application of radiation hard sensors for LHC and ILC,,"The Large Hadron Collider (LHC) currently in operation intends to explore particle physics on the TeV scale. The International Linear Collider (ILC) and the Compact Linear Collider (CLIC) are being designed to measure the properties of particles possibly discovered at the LHC with high precision. Very forward detector systems at these machines are needed for the precise measurement of the luminosity and to approach full polar angle coverage. In the current detector concepts for linear collider detectors two electromagnetic calorimeters, Beam Calorimeter (BeamCal) and Luminosity Calorimeter (LumiCal), are foreseen. Both calorimeters are designed as sandwich calorimeters with tungsten absorber layers instrumented with finely segmented sensors. Due to a large amount of beamstrahlung remnants hitting BeamCal at the innermost radii, the sensors must withstand up to 1 MGy radiation dose per year. In this thesis two types of sensor materials were investigated: single crystal chemical vapour deposition diamonds (scCVDD) and gallium arsenide doped by chromium (GaAs:Cr). The very forward calorimeters ensure coverage for high energy electrons, positrons and photons down to very low polar angles. Within this thesis, simulation studies are presented for different beam parameters of the ILC. A new sensor segmentation was proposed to achieve better reconstruction efficiency of single high-energy electrons, positrons and photons on top of the beamstrahlung background. Only for a few years ago polycrystalline diamond sensors have been used for beam diagnostics in high-energy physics experiments. The Compact Muon Solenoid experiment, CMS, at the LHC is instrumented with several detectors for the Beam Conditions and Radiation Monitoring. The Fast Beam Conditions Monitor (BCM1F) is part of these systems. Here for the first time single crystal diamond sensors have been used. Eight detectors, comprising each a single crystal sensor and front-end electronics, are positioned around the beam pipe on both sides of the interaction region. They monitor the beam halo to protect the inner CMS detectors from adverse beam conditions and ensure high quality data for CMS. In this thesis, BCM1F data is evaluated for intrinsic time resolution and performance under harsh radiation conditions. Furthermore, it is investigated if it can be used for a bunch by bunch on-line luminosity measurement. The second type of sensor, made of GaAs:Cr, was produced in Tomsk State University and tested as a candidate for the BeamCal for future ILC and CLIC detectors. Several GaAs:Cr sensors were characterized in the laboratory for leakage current and capacitances and used for test beam investigations. Two sensors were assembled with a fan-out, front-end and ADC ASICs to build a fully functional prototype of a sensor plane. Several test beam campaigns were done to measure the performance of the system.",,"Novgorodova, Olga",2013,,,OPUS4-2856,Dissertation
"Land-use Planning Recommendations - Adaptation Strategies for a Changing Climate in Ho Chi Minh City, Vietnam: Summary for Decision-Makers",,"Urbanisation is an extreme case of land-use change. The geographical patterns of urban expansion of a city have a direct relationship with its environmental quality, particularly water flows, flooding and urban thermal stress. A key question for urban policy and planning is how to direct these changes in ways that minimise environmental impacts and risks. Since many of the main impacts of climate change in Ho Chi Minh City additionally exhibit a land use dimension, such as the increased frequency of urban flooding events or the intensification of the already existing urban heat island effect, land-use planning and land-use controls can be seen as the most appropriate adaptation management strategy. These recommendations have been developed under the German Ministry for Education and Research Funded research project ''Integrative Urban and Environmental Planning for Adaptation of Ho Chi Minh City to Climate Change"" which is funded as part of the research programme ''Sustainable Development of the Megacities of Tomorrow'' by the German Federal Ministry of Education and Research (BMBF) in close cooperation with the Department of Nature Resources and Environment, Ho Chi Minh City. The main objective was to respond to the needs of the Department of Nature Resource and Environment, Ho Chi Minh City by providing guidance and recommendations that can be used by land-use planners and policy makers to reduce the potential adverse effects of both urbanisation and the current and future effects of climate change. The recommendations have been compiled as a stand-alone document that can be read and understood on their own, however they also contain references to the additional document entitled ""Land-use Planning Recommendations - Adaptation Strategies to a Changing Climate in Ho Chi Minh City"" referenced within this document as LUPR.Eleven specific focus areas were selected (labelledfrom A to K) in combination with the Department of Natural Resources and Environment. For each area the current situation is described and detailed planning recommendations are provided.",,,2013,,,OPUS4-3184,Bericht
12th EEEIC International Conference on Environment and Electrical Engineering - Student Edition : Wroc&#322;aw-Ostrava-Cottbus 20th - 25th of May 2013,,"In the time of increased awareness about the environment problems by the public opinion and also intensive international efforts to reduce emissions of greenhouse gases, as well increase of the generation of electrical energy to facilitate industrial growth, the conference offers broad contribution towards achieving the goals of diversification and sustainable development. Focus of the student conference is to promote the discussion of views from scientists and students from Wroclaw University of Technology, Technical University of Ostrava and Brandenburg Technical University of Cottbus. The conference offers prominent academics and industrial practitioners from all over the world the forum for discussion about the future of electrical energy and environmental issues and presents a base for identifying directions for continuation of research.",,,2013,,,OPUS4-5676,Konferenzveröffentlichung
Structures and processes of the initial ecosystem development phase in an artificial water catchment (Final report CRC/TR 38),,"Objective of the Transregional Collaborative Research Centre (CRC/TR) 38 was the study of structures and processes of the initial ecosystem development. It was assumed that the initial phase is characterized by less structured and therefore less heterogeneous ecosystems. Thus, analysis of young ecosystems in their initial stages should provide better insights into ecosystem functioning. Following this basic concept, the idea of the CRC/TR 38 was to analyze the establishment of new structures and processes which lead to a growing structuring and in consequence to a growing complexity and heterogeneity in an artificially created watershed. Further, with the help of this step-by-step development of the ecosystem it was aimed to learn from occurring feedbacks, which appear between old and newly emerging structures and patterns in order to better understand also the behavior of more mature systems. Special emphasis was placed on the spatial and temporal dynamics of both evolving structures and related processes and their interactions. In summary, the CRC/TR 38 was able to identify a number of structures and processes that are considered to be relevant and specific for young systems.",,"Hüttl, Reinhard F.; Kögel-Knabner, Ingrid; Schulin, Rainer; Gerwin, Werner",2013,,,OPUS4-1682,Bericht
"Investigation of pulverized, pre-dried lignite combustion under oxy-fired conditions in a large-scale laboratory furnace",,"The oxy-fuel combustion process with subsequent CO2 storage has received attention as a promising technology for capturing CO2 from fossil fuel power plants. Recent progress in understanding pulverized coal combustion under oxy-fired conditions is attributable in part to studies performed at laboratory bench-scale. Previous investigations have underlined some significant differences between conventional air-fired and oxy-fired combustion with regard to temperature, heat flux distribution, and pollutant emissions. While most studies provide information on the impacts of O2 concentration in the feed gas, the impact of burner configuration and operating settings on oxy-coal combustion have been investigated by only a handful of studies. The present study addresses the impact of oxy-fired conditions on the chemistry and dynamics of pulverized coal flames generated by a staged feed-gas burner operating with pre-dried lignite. Investigations were carried out in a newly constructed test facility where the combustion takes place in a horizontal up-fired furnace with a rated capacity of 0.40 MWth. Since the focus of this work is on adapting oxy-fuel combustion techniques to existing furnaces, great emphasis is placed on maintaining flame temperatures and heat transfer similar to that of conventional air combustion. The strategy adopted to investigate the impacts of burner settings is divided into theoretical and experimental investigations. In the theoretical study, the combustion-related parameters are calculated based on thermodynamic balances and act as a background for the definition of some important operating settings. Non-reacting flow simulations which include the burner and part of the furnace are performed using a CFD commercial code aimed at a qualitative evaluation of feed gas distribution and swirl strength on the flow pattern formed in the near burner region. These predictions assist in the interpretation of the experimental data and in the calculation of the swirl number at the exit of the burner. During the experimental investigations, the characteristics of diffusion flames were first investigated in a parametric study to evaluate the impact of secondary swirl numbers at three levels and secondary/tertiary flow ratios on the overall combustion performance. The second part of the test program involved detailed in-flame measurements for selected flames. Measurements of local gas temperature, gas species concentrations, and radiative heat flux were performed with standard water-cooled probes with special focus on the near burner region. Theoretical and experimental studies are also carried out under air-fired conditions and used as a benchmark throughout this study. The overall O2 fraction upstream of the burner was kept at 31 vol% and was defined with basis on a similar adiabatic flame temperature as air-firing. Flame stabilization was shown to be strongly dependent on the O2 fraction of the primary stream, feed gas distribution between the secondary and tertiary registers, and strength of the secondary swirl. Type-1 flames operating at a stoichiometric ratio of 1.17 were generated under air-fired and oxy-fired conditions and investigated in detail. Detailed flow pattern and flame structure studies show evidence of radial flame stratification consistent with gradual O2 admixing to the central fuel jet. Increasing the swirl number and the secondary/tertiary flow ratio enhances the mixing of coal particles and increases the temperatures close to burner. Much lower temperatures on the flame axis are observed under oxy-fired conditions. In the same region, higher CO concentrations were also observed, possibly as a result of CO2 dissociation and/or gasification reactions by water vapor and CO2 which contribute to lower temperatures. Very low CO concentration at the furnace exit and high particle burnout indicate that oxy-fired conditions are not an obstacle to achieving a high combustion efficiency for type-1 flames. Although SO2 concentrations were higher under oxy-fired conditions, the emission rates were very similar, indicating that SO2 emissions are exclusively dependent on the sulfur content of the coal. Experimental data obtained from the parametric study and in-flame measurements suggest great potential for NO abatement through flame aerodynamics for oxy-coal combustion. The experiments demonstrate that feed gas staging in a burner is an effective technique for improving the flame stratification in fuel-rich and fuel-lean zones. In particular, a combination of high swirl and high secondary/tertiary flow ratio results in significant NO reduction.",,"Corrêa da Silva, Rodrigo",2013,,,OPUS4-2657,Dissertation
"The digital ""Memory of the World"" : an exploration of documentary practices in the age of digital technology",,"This research is a study of the UNESCO ""Memory of the World"" Programme established with the purpose to increase awareness of the existence and relevance of documentary heritage, and to achieve its universal and permanent accessibility. In this context, digital technology is increasingly used to provide access to documentary heritage but this activity also leads to a series of changes in how documents are understood and handled. Starting from the observation that the conceptual and practical changes triggered by digital technology in the ""Memory of the World"" do not seem to accurately reflect its stated philosophy, this research pursues the aim to critically analyze the possibilities and limits it offers. This analysis is facilitated by a conceptual framework anchored in the medium theory of Harold Innis and his concepts of medium, bias, space and time, and balance, which serve as analytical lenses to closely study selected aspects of digital technology and their influence. Despite popular beliefs that digital technology is most suitable for universal access, the findings of this present research lead to the observation that this cannot really be the case, and it reveals that an over-emphasis on the technical possibilities of digital access is not supportive of the overall purpose of the ""Memory of the World"", leading to the narrowing down of its potential relevance. At first glance, this may suggest not recommending at all the use of digital technology. However, acknowledging that each medium has both limits and possibilities, instead of rejecting digital technology the study searches for solutions that may assist with integrating it in the ""Memory of the World"" in accordance with its overall purpose and philosophy. To this end, three recommendations are elaborated, the same conceptual framework that revealed the limits of digital technology being applied to construct on their possibilities. In order to motivate why following the recommendations of this analysis would be necessary, the study concludes by shifting attention from the relevance of digital technology in the ""Memory of the World"" Programme to the relevance of the Programme in a world changed by digital technology.",,"Prodan, Anca Claudia",2013,,,OPUS4-3013,Dissertation
12. GI/ITG Fachgespräch Sensornetze,,"Drahtlose Sensornetze stellen eine vielversprechende Technologie zur Beobachtung und Beeinflussung von Vorgängen in der realen Welt dar. Autonome Sensorknoten nehmen dabei Parameter der Umwelt durch Sensoren wahr und können diese durch Aktoren beeinflussen. Viele solcher autonomen und ressourcenbeschränkten Knoten kooperieren dabei mittels drahtloser Kommunikation. Die Eigenschaften dieser Knoten und Netze implizieren eine Vielzahl von neuartigen Herausforderungen, die sich in einer regen Forschungsaktivität widerspiegeln. Ziel dieser Reihe von Fachgesprächen ist es, Wissenschaftlerinnen und Wissenschaftlern aus Hochschule und Industrie die Möglichkeit zu einem informellen Gedankenaustausch zu geben und die Kooperation in diesem multidisziplinären Forschungsbereich zu verstärken.",,"Nolte, Jörg",2013,,,OPUS4-2805,Bericht
Intangible cultural heritage of dance as medium for intercultural dialogue : culture assimilator reinterpreted,,"This thesis explores two different models in the use of cultural heritage as a medium for intercultural exchange. This role of cultural heritage is discussed under a larger political framework of intercultural dialogue as a policy approach in managing cultural diversity, with specific reference to the 2008 Council of Europe's White Paper on Intercultural Dialogue. This policy approach is analysed here in terms of the goal in social cohesion and the liberal, procedural commitment in democracy towards cultural and value pluralism, with its relevance discussed in the context of Singapore, which claims an approach of 'communitarianism' upholding 'Asian values'. Against the background of racism problems in Singapore, the staging and interpretation of Indian dance heritage in Singapore will be analysed between a transcultural and a multicultural model of intercultural dialogue, the former focusing on creative engagement to overcome differences in cultural identity, the latter focusing on mutual understanding and respect of differences. As part of the multicultural model, one will analyse cross-cultural interaction as 'critical incidents' based on the 'Culture Assimilator' method (otherwise known as the Intercultural Sensitizer) in intercultural communication training - which German social psychologist Alexander Thomas has repositioned in an intercultural competence framework aligned with systems theory. This framework will be adapted to discuss the aspects of open-mindedness and empathy in intercultural learning through cultural heritage, and to deconstruct cultural differences.",,"Wong, Chee Meng",2013,,,OPUS4-2839,Dissertation
Optical characterization of thin-film Si solar cells and knowledge transfer from bulk mc-Si,,"The aim of this work is to establish tools for optical characterization of defects in thin-film silicon solar cells. This is related to a challenging process of setup adjustments and careful interpretation of the measured raw data because of several artifacts and effects, which are typical for thin films. They are caused by the low layer/sample thickness and the related high impact of interfaces. Therefore, different thin-film samples were investigated to establish a process to correct/minimize these thin-film effects. The possibility of a knowledge transfer from mc-Si wafers with bulk thickness to thin Si films was checked. This would simplify a successful interpretation of the corrected data. Defects in mc-Si were investigated for many decades without the parasitic impact of thin films. Other Si phases, which are limited to thin-film samples, were investigated to learn details about their specific physical properties. These Si phases are amorphous and microcrystalline silicon. Additional to that electroluminescence investigations were performed on mc-Si solar cells. These investigation deals with topics, which are not even understood on bulk materials up to now. This could offer a basic for further knowledge transfers to thin-film Si.",,"Klossek, André",2013,,,OPUS4-2842,Dissertation
MBE growth and characterization of germanium nanowires,,"Semiconductor nanowires, also called nanorods or nanowhiskers, are of particular interest for various applications in nanotechnology. Especially, germanium as a CMOS compatible material with its good electronic properties has gained renewed interest in recent years due to the availability of modern gate dielectrics. The present work deals with the vapor-liquid-solid growth of germanium nanowires and their characterization. The Growth has been carried out by means of molecular beam epitaxy using differently oriented germanium and silicon substrates whereas gold has been used to create metal catalyst droplets with radii of typically 100 nm and below. All stages from the substrate preparation to the final growth have been investigated in the frame of this work to find significant control parameters that influence the growth result. The droplet formation by means of gold evaporation onto the heated substrates has been investigated extensively on different substrates and for different surface preparations to identify parameters that are crucial for the resulting size distribution. Thereby sticking effects of the droplet circumference turned out to influence the radius distribution significantly. Germanium nanowires have been observed to grow preferentially along the <011> crystallographic directions on all utilized substrate orientations leading to defined possible inclinations of the wires with respect to the substrate normal. In contrast to the faceting known from silicon wires, the sidewalls mainly exhibit four flat {111} facets whereas the tip is roof shaped consisting of another two {111} facets. Different models which describe the inclined growth are presented and discussed. Furthermore, the material transport during the growth has been investigated. The nanowire length was found to be up to eight times larger than the nominal layer thickness according to the total amount of deposited germanium which is explained by surface diffusion towards the nanowires. The diffusion dominated growth regime was confirmed by length-radius-plot showing a decrease of the nanowire length at increasing radii. A temperature dependent diffusion model has been utilized to describe the observed nanowire length as a function of the substrate temperature. Beside conventional nanowires, so-called in-plane nanowires which grow along the substrate surface have been studied. Like their vertically growing counterparts, they also tend to grow along <011> in-plane directions which is particularly distinct on Ge(011) substrates. However, the fraction of nanowires which are aligned along <011> is influenced by substrate imperfections which was intentionally affected by means of wet-chemical substrate preparation. In addition to the nanowire growth, techniques for selective catalyst removal as well as for nanowire embedding in an insulating, transparent matrix have been established which can be important prerequisites for further nanowire processing in terms of electric or optoelectronic applications.",,"Schmidtbauer, Jan",2013,,,OPUS4-2772,Dissertation
Enabling functional tests of asynchronous circuits using a test processor solution,,"During the last years, the asynchronous design style has been rediscovered as a potential solution to upcoming design issues in deep-submicron technologies. However, besides the lack of commercial tools supporting this design style, one major challenge is the test of asynchronous designs. Especially their event-driven behavior leads to problems during test. Basically, the timing of asynchronous circuits is determined by gate and wire delays that are sensitive to variations of environmental parameters (process, voltage and temperature). This leads to uncertainties in the timing of the responses. Consequently, standard commercial test systems cannot be used, because such systems read the responses at specific cycles and, therefore, could reject fault-free devices. Furthermore, available hardware testers are, in principle, not designed to react to signal events from the design-under-test as it is necessary to establish asynchronous communication via handshake signalling. As a result, even simple functional tests that only apply stimuli and read the responses of the design-under-test cannot be realized without preparatory measures. This work addresses these issues and proposes a concept to enable functional tests of asynchronous designs. The concept is based on a special test processor that provides generic interfaces used to establish asynchronous handshake communication with a device-under-test. By this, elastic functional tests can be realized that overcome the static timing of conventional tests and emulate the real operating environment of the design. Apart from the generic test processor architecture, an essential part of the concept deals with the establishment of the processor as a stand alone or embedded test equipment. A workflow is provided that describes how the device-under-test can be embedded into the test processor environment for performing the tests. Besides the interconnection between the asynchronous design and the test processor, this especially includes the generation of programs that realize the functional tests of the design. A methodology is introduced that generates the desired programs for the processor from a standard functional simulation of the design-under-test. Based on the generic concept, a framework including both a test processor implementation and the realization of the program generation is delivered. In order to evaluate the entire concept, this framework has been applied to functionally test an asynchronous arithmetic-logic-unit. In combination with additional experiments, conducted to determine the required resources, it has been shown that the introduced concept is a suitable approach to test asynchronous designs.",,"Zeidler, Steffen",2013,,,OPUS4-2880,Dissertation
